{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfa39F4lsLf3"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "## **Procesamiento de lenguaje natural**\n",
        "# **Desafio 4: Modelo de lenguaje - QA BOT**\n",
        "\n",
        "Se buscará construir un bot de preguntas y respuestas adaptando el ejemplo trabajado en clase del modelo traductor seq-to-seq basado en LSTMs.\n",
        "\n",
        "Utilizaremos el dataset de preguntas y respuestas de **SQAC (Spanish Question-Answering Corpus)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqO0PRcFsPTe"
      },
      "source": [
        "### **0. Datos e imports**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown --quiet"
      ],
      "metadata": {
        "id": "FGmtK8J19PNk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq3YXak9sGHd"
      },
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgYatMIdk_eT",
        "outputId": "c114f01c-89cf-4336-9fce-b89dbc45e02b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torchinfo\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYpIWGaXxfKe",
        "outputId": "75660a7e-b37f-4164-ff36-ff8dd31fd9f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "if os.access('torch_helpers.py', os.F_OK) is False:\n",
        "    if platform.system() == 'Windows':\n",
        "        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n",
        "    else:\n",
        "        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"
      ],
      "metadata": {
        "id": "GHFPS5KNxgR9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### > Descarga de datos"
      ],
      "metadata": {
        "id": "5BFiCH8nxoIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se utilizaran datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA)."
      ],
      "metadata": {
        "id": "4oOJmvMlkWEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown --quiet"
      ],
      "metadata": {
        "id": "hEhdjpGQkiE4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "if os.access('data_volunteers.json', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n",
        "    output = 'data_volunteers.json'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssB0HnggkkiK",
        "outputId": "66ad352a-386f-4076-eb4d-6f50506066f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El dataset ya se encuentra descargado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "text_file = \"data_volunteers.json\"\n",
        "with open(text_file) as f:\n",
        "    data = json.load(f) # la variable data será un diccionario"
      ],
      "metadata": {
        "id": "gjoWRrIqkkf0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observar los campos disponibles en cada linea del dataset\n",
        "data[0].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAfmXkH_kkUY",
        "outputId": "00074dc7-e47c-48b7-c680-f2e664df6302"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_in = []\n",
        "chat_out = []\n",
        "\n",
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "max_len = 30\n",
        "\n",
        "def clean_text(txt):\n",
        "    txt = txt.lower()\n",
        "    txt.replace(\"\\'d\", \" had\")\n",
        "    txt.replace(\"\\'s\", \" is\")\n",
        "    txt.replace(\"\\'m\", \" am\")\n",
        "    txt.replace(\"don't\", \"do not\")\n",
        "    txt = re.sub(r'\\W+', ' ', txt)\n",
        "\n",
        "    return txt\n",
        "\n",
        "for line in data:\n",
        "    for i in range(len(line['dialog'])-1):\n",
        "        # vamos separando el texto en \"preguntas\" (chat_in)\n",
        "        # y \"respuestas\" (chat_out)\n",
        "        chat_in = clean_text(line['dialog'][i]['text'])\n",
        "        chat_out = clean_text(line['dialog'][i+1]['text'])\n",
        "\n",
        "        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n",
        "            continue\n",
        "\n",
        "        input_sentence, output = chat_in, chat_out\n",
        "\n",
        "        # output sentence (decoder_output) tiene\n",
        "        output_sentence = output + \" \"\n",
        "        # output sentence input (decoder_input) tiene\n",
        "        output_sentence_input = \" \" + output\n",
        "\n",
        "        input_sentences.append(input_sentence)\n",
        "        output_sentences.append(output_sentence)\n",
        "        output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rViiIeGtk0C6",
        "outputId": "9845ef57-ef19-411b-94da-9479fb30e87b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows utilizadas: 6033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences[1], output_sentences[1], output_sentences_inputs[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrS4qxCUk2Hv",
        "outputId": "a00a76fa-fa80-4237-d9ee-31d306a3b456"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('hi how are you ', 'not bad and you  ', ' not bad and you ')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-ynUNP5xp6"
      },
      "source": [
        "### 2 - Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WAZGOTfGyha"
      },
      "source": [
        "# Definir el tamaño máximo del vocabulario\n",
        "MAX_VOCAB_SIZE = 8000"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF1W6peoFGXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f7b2d2-2d20-4c59-9144-806246ba3697"
      },
      "source": [
        "from torch_helpers import Tokenizer\n",
        "\n",
        "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Sentencia de entrada más larga:\", max_input_len)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 1799\n",
            "Sentencia de entrada más larga: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBzdKiTVIBYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5ef09ab-9685-42e9-e5b4-8db2027b97c4"
      },
      "source": [
        "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
        "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
        "special_tokens = [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"]\n",
        "\n",
        "# Los agregás manualmente antes de entrenar el tokenizer\n",
        "output_tokenizer = Tokenizer(\n",
        "    num_words=MAX_VOCAB_SIZE,\n",
        "    filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n'\n",
        ")\n",
        "\n",
        "output_tokenizer.fit_on_texts(special_tokens + output_sentences)\n",
        "\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "idx2word_outputs = {i: w for w, i in word2idx_outputs.items()}\n",
        "\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
        "\n",
        "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer <sos>\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Sentencia de salida más larga:\", max_out_len)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 1808\n",
            "Sentencia de salida más larga: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_TOKEN = output_tokenizer.word_index[\"<pad>\"]\n",
        "UNK_TOKEN = output_tokenizer.word_index[\"<unk>\"]\n",
        "SOS_TOKEN = output_tokenizer.word_index[\"<sos>\"]\n",
        "EOS_TOKEN = output_tokenizer.word_index[\"<eos>\"]"
      ],
      "metadata": {
        "id": "mHl5CDNz2zQX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgLC706EQx3p"
      },
      "source": [
        "# Por una cuestion de que no explote la RAM se limitará el tamaño de las sentencias de entrada\n",
        "# a la mitad:\n",
        "max_input_len = 18\n",
        "max_out_len = 18"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Vocab real: {len(word2idx_outputs)}\")\n",
        "print(f\"MAX_VOCAB_SIZE: {MAX_VOCAB_SIZE}\")\n",
        "print(f\"Embeddings realmente usados: {len(output_tokenizer.word_index)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogl5XMXtxFrq",
        "outputId": "ac5a6a8b-6777-45b8-8203-aaebb97400e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab real: 1808\n",
            "MAX_VOCAB_SIZE: 8000\n",
            "Embeddings realmente usados: 1808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGOn9N57IuYz"
      },
      "source": [
        "> A la hora de realiza padding es importante teneer en cuenta que **en el encoder los ceros se agregan al comienzo** y **en el decoder al final**.\n",
        "\n",
        "> Esto es porque la salida del encoder está basado en las últimas palabras de la sentencia (son las más importantes), mientras que en el decoder está basado en el comienzo de la secuencia de salida ya que es la realimentación del sistema y termina con fin de sentencia."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_TOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ochiy5VP670t",
        "outputId": "25b71e43-d506-4e12-c096-32b38791d354"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1800"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0Ob4hAWJkcv"
      },
      "source": [
        "import torch\n",
        "\n",
        "def pad_sequences_torch(sequences, maxlen, padding='pre', padding_value=PAD_TOKEN):\n",
        "    \"\"\"\n",
        "    Versión robusta: ignora secuencias vacías y evita RuntimeError.\n",
        "\n",
        "    Args:\n",
        "        sequences (list[list[int]]): lista de secuencias (ej. token ids)\n",
        "        maxlen (int): longitud máxima final de cada secuencia\n",
        "        padding ('pre' or 'post'): dónde agregar el padding\n",
        "        padding_value (int): valor de padding (por defecto 0)\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: tensor de tamaño (num_seqs, maxlen)\n",
        "    \"\"\"\n",
        "    n = len(sequences)\n",
        "    padded = torch.full((n, maxlen), padding_value, dtype=torch.long)\n",
        "\n",
        "    for i, seq in enumerate(sequences):\n",
        "        # ⚠️ si la secuencia está vacía, saltar\n",
        "        if len(seq) == 0:\n",
        "            continue\n",
        "\n",
        "        seq = torch.tensor(seq[:maxlen], dtype=torch.long)\n",
        "        seq_len = len(seq)\n",
        "\n",
        "        if padding == 'pre':\n",
        "            padded[i, -seq_len:] = seq\n",
        "        else:  # 'post'\n",
        "            padded[i, :seq_len] = seq\n",
        "\n",
        "    return padded\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_sequences = pad_sequences_torch(input_integer_seq, maxlen=max_input_len, padding='pre')\n",
        "decoder_input_sequences = pad_sequences_torch(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "\n",
        "print(\"Encoder shape:\", encoder_input_sequences.shape)\n",
        "print(\"Decoder shape:\", decoder_input_sequences.shape)\n",
        "print(\"Encoder example:\\n\", encoder_input_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VySR1pzx9UG",
        "outputId": "f17bd62f-077c-4988-9d45-388a02f1a31b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder shape: torch.Size([6033, 18])\n",
            "Decoder shape: torch.Size([6033, 18])\n",
            "Encoder example:\n",
            " tensor([[1800, 1800, 1800,  ..., 1800, 1800,   19],\n",
            "        [1800, 1800, 1800,  ...,   10,    7,    2],\n",
            "        [1800, 1800, 1800,  ..., 1800, 1800,   11],\n",
            "        ...,\n",
            "        [1800, 1800, 1800,  ..., 1800, 1800,   19],\n",
            "        [1800, 1800, 1800,  ...,    3,    8,   13],\n",
            "        [1800, 1800, 1800,  ...,    2,  596,    3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output_sequences = pad_sequences_torch(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_output_sequences shape:\", decoder_output_sequences.shape)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HLAwGVjm-zN",
        "outputId": "b9b7b3bf-da73-44c3-c5c1-9afa1e94f4de"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder_output_sequences shape: torch.Size([6033, 18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK4blEEsRQv3"
      },
      "source": [
        "> La última capa del modelo (softmax) necesita que los valores de salida\n",
        "del decoder (decoder_sequences) estén en formato oneHotEncoder.\n",
        "\n",
        "> Se utiliza \"decoder_output_sequences\" con la misma estrategia que se transformó la entrada del decoder."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(Dataset):\n",
        "    def __init__(self, encoder_input, decoder_input, decoder_output):\n",
        "        self.encoder_inputs = encoder_input.long()\n",
        "        self.decoder_inputs = decoder_input.long()\n",
        "        self.decoder_outputs = decoder_output.long()  # sin one-hot para CrossEntropyLoss\n",
        "\n",
        "        self.len = len(self.encoder_inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.encoder_inputs[idx],\n",
        "            self.decoder_inputs[idx],\n",
        "            self.decoder_outputs[idx]\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\n",
        "data_set = QADataset(encoder_input_sequences, decoder_input_sequences, decoder_output_sequences)\n",
        "\n",
        "encoder_input_size = data_set.encoder_inputs.shape[1]\n",
        "print(\"encoder_input_size:\", encoder_input_size)\n",
        "\n",
        "decoder_input_size = data_set.decoder_inputs.shape[1]\n",
        "print(\"decoder_input_size:\", decoder_input_size)\n",
        "\n",
        "output_dim = data_set.decoder_outputs.shape\n",
        "print(\"Output dim\", output_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD0bpM32yWfB",
        "outputId": "61e49598-687f-404c-a1f1-f3dd4f1d23d8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_input_size: 18\n",
            "decoder_input_size: 18\n",
            "Output dim torch.Size([6033, 18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "valid_set_size = int(data_set.len * 0.2)\n",
        "train_set_size = data_set.len - valid_set_size\n",
        "\n",
        "train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n",
        "valid_set = torch.utils.data.Subset(data_set, range(train_set_size, data_set.len))\n",
        "\n",
        "print(\"Tamaño del conjunto de entrenamiento:\", len(train_set))\n",
        "print(\"Tamaño del conjunto de validacion:\", len(valid_set))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUDPZeuAU1RI",
        "outputId": "d2399d3e-e71a-4004-c5b4-b44b7c666388"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: 4827\n",
            "Tamaño del conjunto de validacion: 1206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJrcTRZ5z16S",
        "outputId": "8d38bc8c-ed95-4572-f224-beff03c4fd20"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello ',\n",
              " 'hi how are you ',\n",
              " 'hi ',\n",
              " 'hi ',\n",
              " 'hi ',\n",
              " 'where are you working ',\n",
              " 'bro ',\n",
              " 'where are you from ',\n",
              " 'i am from russia and you ',\n",
              " 'i hate them most of the time ']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AU9bnZZ0Gsl",
        "outputId": "31cd7a97-24b0-4393-a6af-45e8a8482f59"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi how are you  ',\n",
              " 'not bad and you  ',\n",
              " 'hello  ',\n",
              " 'hello  ',\n",
              " 'hello how are you today  ',\n",
              " 'bro  ',\n",
              " 'where are you from  ',\n",
              " 'i am from russia and you  ',\n",
              " 'i am from the united states  ',\n",
              " 'you are racist  ']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJIsLBbj6rg"
      },
      "source": [
        "### **3 - Preparar los embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OcT-DLzkHS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56c2e02e-72c5-43a2-a0e5-28077a9246c9"
      },
      "source": [
        "import os\n",
        "import gdown\n",
        "if os.access('gloveembedding.pkl', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1wlDBOrxPq2-3htQ6ryVo7K1XnzLcfh4r&export=download'\n",
        "    output = 'gloveembedding.pkl'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"Los embeddings gloveembedding.pkl ya están descargados\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los embeddings gloveembedding.pkl ya están descargados\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgqtV8GpkSc8"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "class WordsEmbeddings(object):\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def __init__(self):\n",
        "        # load the embeddings\n",
        "        words_embedding_pkl = Path(self.PKL_PATH)\n",
        "        if not words_embedding_pkl.is_file():\n",
        "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
        "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
        "            embeddings = self.convert_model_to_pickle()\n",
        "        else:\n",
        "            embeddings = self.load_model_from_pickle()\n",
        "        self.embeddings = embeddings\n",
        "        # build the vocabulary hashmap\n",
        "        index = np.arange(self.embeddings.shape[0])\n",
        "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
        "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
        "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
        "\n",
        "    def get_words_embeddings(self, words):\n",
        "        words_idxs = self.words2idxs(words)\n",
        "        return self.embeddings[words_idxs]['embedding']\n",
        "\n",
        "    def words2idxs(self, words):\n",
        "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
        "\n",
        "    def idxs2words(self, idxs):\n",
        "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
        "\n",
        "    def load_model_from_pickle(self):\n",
        "        self.logger.debug(\n",
        "            'loading words embeddings from pickle {}'.format(\n",
        "                self.PKL_PATH\n",
        "            )\n",
        "        )\n",
        "        max_bytes = 2**28 - 1 # 256MB\n",
        "        bytes_in = bytearray(0)\n",
        "        input_size = os.path.getsize(self.PKL_PATH)\n",
        "        with open(self.PKL_PATH, 'rb') as f_in:\n",
        "            for _ in range(0, input_size, max_bytes):\n",
        "                bytes_in += f_in.read(max_bytes)\n",
        "        embeddings = pickle.loads(bytes_in)\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "    def convert_model_to_pickle(self):\n",
        "        # create a numpy strctured array:\n",
        "        # word     embedding\n",
        "        # U50      np.float32[]\n",
        "        # word_1   a, b, c\n",
        "        # word_2   d, e, f\n",
        "        # ...\n",
        "        # word_n   g, h, i\n",
        "        self.logger.debug(\n",
        "            'converting and loading words embeddings from text file {}'.format(\n",
        "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
        "            )\n",
        "        )\n",
        "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
        "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
        "        structure = np.dtype(structure)\n",
        "        # load numpy array from disk using a generator\n",
        "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
        "            embeddings_gen = (\n",
        "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
        "                if len(line.split()[1:]) == self.N_FEATURES\n",
        "            )\n",
        "            embeddings = np.fromiter(embeddings_gen, structure)\n",
        "        # add a null embedding\n",
        "        null_embedding = np.array(\n",
        "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
        "            dtype=structure\n",
        "        )\n",
        "        embeddings = np.concatenate([embeddings, null_embedding])\n",
        "        # dump numpy array to disk using pickle\n",
        "        max_bytes = 2**28 - 1 # # 256MB\n",
        "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.PKL_PATH, 'wb') as f_out:\n",
        "            for idx in range(0, len(bytes_out), max_bytes):\n",
        "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class GloveEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
        "    PKL_PATH = 'gloveembedding.pkl'\n",
        "    N_FEATURES = 50\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "class FasttextEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
        "    PKL_PATH = 'fasttext.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mosj2-x-kXBK"
      },
      "source": [
        "model_embeddings = GloveEmbeddings()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9FS8ca1ke_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd1d48c-1be3-4f1a-c492-0d3acf376748"
      },
      "source": [
        "print(\"preparing embedding matrix...\")\n",
        "embed_dim = model_embeddings.N_FEATURES\n",
        "words_not_found = []\n",
        "\n",
        "special_tokens = [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"]\n",
        "for t in special_tokens:\n",
        "    if t not in word2idx_inputs:\n",
        "        word2idx_inputs[t] = len(word2idx_inputs) + 1\n",
        "\n",
        "nb_words = len(word2idx_inputs)\n",
        "embedding_matrix = np.zeros((nb_words + 1, embed_dim))\n",
        "\n",
        "for word, i in word2idx_inputs.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "\n",
        "    emb_vec = model_embeddings.get_words_embeddings([word])\n",
        "    if emb_vec is not None and len(emb_vec) > 0:\n",
        "        embedding_matrix[i] = emb_vec[0]\n",
        "    else:\n",
        "        words_not_found.append(word)\n",
        "        embedding_matrix[i] = np.random.normal(scale=0.6, size=(embed_dim,))\n",
        "\n",
        "# asignar tokens especiales explícitamente\n",
        "embedding_matrix[word2idx_inputs[\"<pad>\"]] = np.zeros((embed_dim,))\n",
        "for tok in [\"<unk>\", \"<sos>\", \"<eos>\"]:\n",
        "    embedding_matrix[word2idx_inputs[tok]] = np.random.normal(scale=0.6, size=(embed_dim,))\n",
        "\n",
        "print(f\"number of null word embeddings: {np.sum(np.sum(embedding_matrix, axis=1) == 0)}\")\n",
        "print(f\"coverage: {(1 - np.sum(np.sum(embedding_matrix, axis=1) == 0)/embedding_matrix.shape[0])*100:.2f}%\")\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preparing embedding matrix...\n",
            "number of null word embeddings: 140\n",
            "coverage: 92.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vKbhjtIwPgM"
      },
      "source": [
        "### **4 - Entrenar el modelo**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_acc(y_pred, y_true):\n",
        "    \"\"\"\n",
        "    Calcula accuracy secuencia a secuencia.\n",
        "    \"\"\"\n",
        "    y_pred_tags = y_pred.argmax(dim=-1)\n",
        "    correct = (y_pred_tags == y_true).float()\n",
        "    acc = correct.sum() / correct.numel()\n",
        "    return acc\n",
        "\n",
        "\n",
        "def train(model, train_loader, valid_loader, optimizer, criterion, epochs=30):\n",
        "    train_loss, train_accuracy = [], []\n",
        "    valid_loss, valid_accuracy = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_train_loss, epoch_train_acc = 0.0, 0.0\n",
        "\n",
        "        for train_encoder_input, train_decoder_input, train_target in train_loader:\n",
        "            # --- mover a GPU ---\n",
        "            train_encoder_input = train_encoder_input.to(device)\n",
        "            train_decoder_input = train_decoder_input.to(device)\n",
        "            train_target = train_target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # --- forward ---\n",
        "            output = model(train_encoder_input, train_decoder_input)  # (batch, seq_len, vocab)\n",
        "\n",
        "            # --- calcular loss (vectorizado) ---\n",
        "            loss = criterion(\n",
        "                output.view(-1, output.shape[-1]),   # (batch*seq, vocab)\n",
        "                train_target.view(-1)                # (batch*seq)\n",
        "            )\n",
        "\n",
        "            # --- backward ---\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # --- metrics ---\n",
        "            epoch_train_loss += loss.item()\n",
        "            epoch_train_acc += sequence_acc(output, train_target).item()\n",
        "\n",
        "        # promedio de epoch\n",
        "        train_loss.append(epoch_train_loss / len(train_loader))\n",
        "        train_accuracy.append(epoch_train_acc / len(train_loader))\n",
        "\n",
        "        # =====================================================\n",
        "        # 🔹 VALIDACIÓN\n",
        "        # =====================================================\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_encoder_input, val_decoder_input, val_target = next(iter(valid_loader))\n",
        "            val_encoder_input = val_encoder_input.to(device)\n",
        "            val_decoder_input = val_decoder_input.to(device)\n",
        "            val_target = val_target.to(device)\n",
        "\n",
        "            val_output = model(val_encoder_input, val_decoder_input)\n",
        "\n",
        "            val_loss = criterion(\n",
        "                val_output.view(-1, val_output.shape[-1]),\n",
        "                val_target.view(-1)\n",
        "            ).item()\n",
        "\n",
        "            val_acc = sequence_acc(val_output, val_target).item()\n",
        "\n",
        "        valid_loss.append(val_loss)\n",
        "        valid_accuracy.append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1:02}/{epochs} | \"\n",
        "              f\"Train Loss: {train_loss[-1]:.3f} | Train Acc: {train_accuracy[-1]:.3f} | \"\n",
        "              f\"Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.3f}\")\n",
        "\n",
        "    return {\n",
        "        \"loss\": train_loss,\n",
        "        \"accuracy\": train_accuracy,\n",
        "        \"val_loss\": valid_loss,\n",
        "        \"val_accuracy\": valid_accuracy,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "khMYFwFqolTk"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "PAD_TOKEN = word2idx_inputs.get(\"<pad>\", 0)\n",
        "VOCAB_SIZE = embedding_matrix.shape[0]\n",
        "EMBED_DIM = embedding_matrix.shape[1]\n",
        "\n",
        "print(f\"✅ Using device: {device}\")\n",
        "print(f\"Vocab size: {VOCAB_SIZE}, Embedding dim: {EMBED_DIM}\")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Definición de modelos\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_matrix, pad_token, hidden_size=128, num_layers=1, train_embeddings=True):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_matrix.shape[1], padding_idx=pad_token)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        self.embedding.weight.requires_grad = train_embeddings  # desfreezado\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_matrix.shape[1],\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True,\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        outputs, (h, c) = self.lstm(emb)\n",
        "        return (h, c)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_matrix, pad_token, hidden_size=128, num_layers=1, train_embeddings=True):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_matrix.shape[1], padding_idx=pad_token)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        self.embedding.weight.requires_grad = train_embeddings  # desfreezado\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_matrix.shape[1],\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True,\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        emb = self.embedding(x)\n",
        "        output, (h, c) = self.lstm(emb, prev_state)\n",
        "        logits = self.fc(output[:, -1, :])\n",
        "        return logits, (h, c)\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, encoder_input, decoder_input):\n",
        "        batch_size, seq_len = decoder_input.shape\n",
        "        vocab_size = self.decoder.fc.out_features\n",
        "        outputs = torch.zeros(batch_size, seq_len, vocab_size).to(encoder_input.device)\n",
        "        prev_state = self.encoder(encoder_input)\n",
        "\n",
        "        input_tok = decoder_input[:, 0:1]\n",
        "        for t in range(seq_len):\n",
        "            output, prev_state = self.decoder(input_tok, prev_state)\n",
        "            outputs[:, t, :] = output\n",
        "            input_tok = decoder_input[:, t:t+1]  # teacher forcing\n",
        "        return outputs\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Instanciación\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "encoder = Encoder(VOCAB_SIZE, embedding_matrix, PAD_TOKEN)\n",
        "decoder = Decoder(VOCAB_SIZE, embedding_matrix, PAD_TOKEN)\n",
        "model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"✅ Modelo, optimizer y criterion inicializados correctamente\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K82gEEpJ4nUt",
        "outputId": "a547a48c-0508-43dc-994a-8616736397b0"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using device: cuda\n",
            "Vocab size: 1804, Embedding dim: 50\n",
            "✅ Modelo, optimizer y criterion inicializados correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_matrix.shape[0], \"==\", len(word2idx_inputs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prng84mr6lW4",
        "outputId": "25466377-02f4-415e-fba8-1d7940a365ef"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1804 == 1803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_TOKEN = word2idx_inputs.get(\"<pad>\", 0)\n",
        "PAD_TOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTgrUs9v6qc_",
        "outputId": "0c37912c-f626-4c74-ffa5-afb06ca67b8a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1800"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2nprd6Pp1TG",
        "outputId": "b5208a8f-b159-4bdc-e542-5805874bde41"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(1804, 50, padding_idx=1800)\n",
              "    (lstm): LSTM(50, 128, batch_first=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(1804, 50, padding_idx=1800)\n",
              "    (lstm): LSTM(50, 128, batch_first=True)\n",
              "    (fc): Linear(in_features=128, out_features=1804, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    valid_loader,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    epochs=50\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDB0KWIegt8s",
        "outputId": "42105ba8-c098-46a1-c0ac-edc07bb064b5"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01/50 | Train Loss: 2.858 | Train Acc: 0.114 | Val Loss: 3.260 | Val Acc: 0.087\n",
            "Epoch 02/50 | Train Loss: 2.644 | Train Acc: 0.120 | Val Loss: 3.078 | Val Acc: 0.095\n",
            "Epoch 03/50 | Train Loss: 2.469 | Train Acc: 0.126 | Val Loss: 2.944 | Val Acc: 0.104\n",
            "Epoch 04/50 | Train Loss: 2.320 | Train Acc: 0.131 | Val Loss: 2.877 | Val Acc: 0.109\n",
            "Epoch 05/50 | Train Loss: 2.184 | Train Acc: 0.134 | Val Loss: 2.816 | Val Acc: 0.113\n",
            "Epoch 06/50 | Train Loss: 2.069 | Train Acc: 0.136 | Val Loss: 2.730 | Val Acc: 0.113\n",
            "Epoch 07/50 | Train Loss: 1.962 | Train Acc: 0.138 | Val Loss: 2.701 | Val Acc: 0.122\n",
            "Epoch 08/50 | Train Loss: 1.869 | Train Acc: 0.141 | Val Loss: 2.634 | Val Acc: 0.122\n",
            "Epoch 09/50 | Train Loss: 1.779 | Train Acc: 0.144 | Val Loss: 2.640 | Val Acc: 0.125\n",
            "Epoch 10/50 | Train Loss: 1.695 | Train Acc: 0.146 | Val Loss: 2.619 | Val Acc: 0.120\n",
            "Epoch 11/50 | Train Loss: 1.621 | Train Acc: 0.149 | Val Loss: 2.584 | Val Acc: 0.127\n",
            "Epoch 12/50 | Train Loss: 1.539 | Train Acc: 0.152 | Val Loss: 2.577 | Val Acc: 0.132\n",
            "Epoch 13/50 | Train Loss: 1.472 | Train Acc: 0.154 | Val Loss: 2.560 | Val Acc: 0.130\n",
            "Epoch 14/50 | Train Loss: 1.406 | Train Acc: 0.157 | Val Loss: 2.573 | Val Acc: 0.132\n",
            "Epoch 15/50 | Train Loss: 1.341 | Train Acc: 0.160 | Val Loss: 2.536 | Val Acc: 0.132\n",
            "Epoch 16/50 | Train Loss: 1.284 | Train Acc: 0.162 | Val Loss: 2.554 | Val Acc: 0.134\n",
            "Epoch 17/50 | Train Loss: 1.225 | Train Acc: 0.165 | Val Loss: 2.550 | Val Acc: 0.135\n",
            "Epoch 18/50 | Train Loss: 1.172 | Train Acc: 0.167 | Val Loss: 2.523 | Val Acc: 0.130\n",
            "Epoch 19/50 | Train Loss: 1.124 | Train Acc: 0.169 | Val Loss: 2.550 | Val Acc: 0.134\n",
            "Epoch 20/50 | Train Loss: 1.078 | Train Acc: 0.171 | Val Loss: 2.569 | Val Acc: 0.135\n",
            "Epoch 21/50 | Train Loss: 1.037 | Train Acc: 0.173 | Val Loss: 2.576 | Val Acc: 0.132\n",
            "Epoch 22/50 | Train Loss: 0.995 | Train Acc: 0.175 | Val Loss: 2.580 | Val Acc: 0.130\n",
            "Epoch 23/50 | Train Loss: 0.956 | Train Acc: 0.176 | Val Loss: 2.606 | Val Acc: 0.128\n",
            "Epoch 24/50 | Train Loss: 0.919 | Train Acc: 0.178 | Val Loss: 2.639 | Val Acc: 0.130\n",
            "Epoch 25/50 | Train Loss: 0.887 | Train Acc: 0.179 | Val Loss: 2.671 | Val Acc: 0.132\n",
            "Epoch 26/50 | Train Loss: 0.854 | Train Acc: 0.181 | Val Loss: 2.645 | Val Acc: 0.127\n",
            "Epoch 27/50 | Train Loss: 0.826 | Train Acc: 0.182 | Val Loss: 2.693 | Val Acc: 0.132\n",
            "Epoch 28/50 | Train Loss: 0.795 | Train Acc: 0.184 | Val Loss: 2.690 | Val Acc: 0.130\n",
            "Epoch 29/50 | Train Loss: 0.767 | Train Acc: 0.186 | Val Loss: 2.673 | Val Acc: 0.130\n",
            "Epoch 30/50 | Train Loss: 0.741 | Train Acc: 0.187 | Val Loss: 2.703 | Val Acc: 0.137\n",
            "Epoch 31/50 | Train Loss: 0.716 | Train Acc: 0.188 | Val Loss: 2.756 | Val Acc: 0.128\n",
            "Epoch 32/50 | Train Loss: 0.693 | Train Acc: 0.189 | Val Loss: 2.744 | Val Acc: 0.132\n",
            "Epoch 33/50 | Train Loss: 0.668 | Train Acc: 0.191 | Val Loss: 2.755 | Val Acc: 0.132\n",
            "Epoch 34/50 | Train Loss: 0.646 | Train Acc: 0.192 | Val Loss: 2.789 | Val Acc: 0.134\n",
            "Epoch 35/50 | Train Loss: 0.623 | Train Acc: 0.193 | Val Loss: 2.777 | Val Acc: 0.137\n",
            "Epoch 36/50 | Train Loss: 0.603 | Train Acc: 0.193 | Val Loss: 2.804 | Val Acc: 0.135\n",
            "Epoch 37/50 | Train Loss: 0.583 | Train Acc: 0.195 | Val Loss: 2.856 | Val Acc: 0.135\n",
            "Epoch 38/50 | Train Loss: 0.564 | Train Acc: 0.196 | Val Loss: 2.878 | Val Acc: 0.134\n",
            "Epoch 39/50 | Train Loss: 0.545 | Train Acc: 0.197 | Val Loss: 2.895 | Val Acc: 0.130\n",
            "Epoch 40/50 | Train Loss: 0.528 | Train Acc: 0.198 | Val Loss: 2.902 | Val Acc: 0.132\n",
            "Epoch 41/50 | Train Loss: 0.513 | Train Acc: 0.199 | Val Loss: 2.966 | Val Acc: 0.134\n",
            "Epoch 42/50 | Train Loss: 0.493 | Train Acc: 0.199 | Val Loss: 2.957 | Val Acc: 0.134\n",
            "Epoch 43/50 | Train Loss: 0.477 | Train Acc: 0.201 | Val Loss: 3.017 | Val Acc: 0.130\n",
            "Epoch 44/50 | Train Loss: 0.467 | Train Acc: 0.201 | Val Loss: 3.018 | Val Acc: 0.134\n",
            "Epoch 45/50 | Train Loss: 0.447 | Train Acc: 0.202 | Val Loss: 3.003 | Val Acc: 0.128\n",
            "Epoch 46/50 | Train Loss: 0.433 | Train Acc: 0.203 | Val Loss: 3.043 | Val Acc: 0.132\n",
            "Epoch 47/50 | Train Loss: 0.421 | Train Acc: 0.204 | Val Loss: 3.098 | Val Acc: 0.132\n",
            "Epoch 48/50 | Train Loss: 0.406 | Train Acc: 0.205 | Val Loss: 3.098 | Val Acc: 0.132\n",
            "Epoch 49/50 | Train Loss: 0.395 | Train Acc: 0.205 | Val Loss: 3.121 | Val Acc: 0.134\n",
            "Epoch 50/50 | Train Loss: 0.382 | Train Acc: 0.206 | Val Loss: 3.141 | Val Acc: 0.132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_count = range(1, len(history1['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history1['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history1['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "pZzm3tx059Zv",
        "outputId": "349e6d55-ba8c-4172-aa4e-cef30a26538d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Modelo con embeddings freezados"
      ],
      "metadata": {
        "id": "swlBRvLJ-U9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(VOCAB_SIZE, embedding_matrix, PAD_TOKEN, train_embeddings=False)\n",
        "decoder = Decoder(VOCAB_SIZE, embedding_matrix, PAD_TOKEN,  train_embeddings=False)\n",
        "model_freezed = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"✅ Modelo, optimizer y criterion inicializados correctamente\")\n",
        "\n",
        "history2 = train(\n",
        "    model_freezed,\n",
        "    train_loader,\n",
        "    valid_loader,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    epochs=50\n",
        ")\n",
        "\n",
        "epoch_count = range(1, len(history2['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history2['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history2['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9j2rqeYo-UcH",
        "outputId": "e930e437-9e14-43a4-ee73-1ddafce0334c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo, optimizer y criterion inicializados correctamente\n",
            "Epoch 01/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 02/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 03/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 04/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 05/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 06/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 07/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 08/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 09/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 10/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 11/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 12/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 13/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 14/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 15/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 16/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 17/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 18/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 19/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 20/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 21/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 22/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 23/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 24/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 25/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 26/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 27/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 28/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 29/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 30/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 31/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 32/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 33/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 34/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 35/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 36/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 37/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 38/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 39/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 40/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 41/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 42/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 43/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 44/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 45/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 46/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 47/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 48/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 49/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n",
            "Epoch 50/50 | Train Loss: 7.492 | Train Acc: 0.001 | Val Loss: 7.475 | Val Acc: 0.000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### Modelo con embeddings fastext"
      ],
      "metadata": {
        "id": "8Nrw0fFmFxt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_embeddings = FasttextEmbeddings()\n",
        "\n",
        "print(\"preparing embedding matrix...\")\n",
        "embed_dim = model_embeddings.N_FEATURES\n",
        "words_not_found = []\n",
        "\n",
        "special_tokens = [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"]\n",
        "for t in special_tokens:\n",
        "    if t not in word2idx_inputs:\n",
        "        word2idx_inputs[t] = len(word2idx_inputs) + 1\n",
        "\n",
        "nb_words = len(word2idx_inputs)\n",
        "embedding_matrix = np.zeros((nb_words + 1, embed_dim))\n",
        "\n",
        "for word, i in word2idx_inputs.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "\n",
        "    emb_vec = model_embeddings.get_words_embeddings([word])\n",
        "    if emb_vec is not None and len(emb_vec) > 0:\n",
        "        embedding_matrix[i] = emb_vec[0]\n",
        "    else:\n",
        "        words_not_found.append(word)\n",
        "        embedding_matrix[i] = np.random.normal(scale=0.6, size=(embed_dim,))\n",
        "\n",
        "# asignar tokens especiales explícitamente\n",
        "embedding_matrix[word2idx_inputs[\"<pad>\"]] = np.zeros((embed_dim,))\n",
        "for tok in [\"<unk>\", \"<sos>\", \"<eos>\"]:\n",
        "    embedding_matrix[word2idx_inputs[tok]] = np.random.normal(scale=0.6, size=(embed_dim,))\n",
        "\n",
        "print(f\"number of null word embeddings: {np.sum(np.sum(embedding_matrix, axis=1) == 0)}\")\n",
        "print(f\"coverage: {(1 - np.sum(np.sum(embedding_matrix, axis=1) == 0)/embedding_matrix.shape[0])*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "olUB6q0jGAtH",
        "outputId": "c009bd29-7c63-4e4d-b0fb-50e4a058e2d0"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Words embedding not available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4289618866.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFasttextEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"preparing embedding matrix...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0membed_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_FEATURES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwords_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2687838972.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwords_embedding_pkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mwords_embedding_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWORD_TO_VEC_MODEL_TXT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mwords_embedding_txt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Words embedding not available'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_model_to_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Words embedding not available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(VOCAB_SIZE, embedding_matrix, PAD_TOKEN, train_embeddings=False)\n",
        "decoder = Decoder(VOCAB_SIZE, embedding_matrix, PAD_TOKEN,  train_embeddings=False)\n",
        "model_freezed = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"✅ Modelo, optimizer y criterion inicializados correctamente\")\n",
        "\n",
        "history2 = train(\n",
        "    model_freezed,\n",
        "    train_loader,\n",
        "    valid_loader,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    epochs=50\n",
        ")\n",
        "\n",
        "epoch_count = range(1, len(history2['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history2['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history2['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VMJvbM11Fx8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbwn0ekDy_s2"
      },
      "source": [
        "### **5 - Inferencia**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "\n",
        "def infer(model, input_seq, word2idx_output, idx2word_output,\n",
        "          max_output_len=20, device=\"cuda\",\n",
        "          beam_size=3, temperature=1.0, stochastic=False):\n",
        "    \"\"\"\n",
        "    Inferencia con opción de greedy o beam search.\n",
        "\n",
        "    Args:\n",
        "        model: modelo Seq2Seq (encoder + decoder)\n",
        "        input_seq: secuencia tokenizada de entrada (lista o tensor)\n",
        "        word2idx_output: vocab del decoder (str → int)\n",
        "        idx2word_output: vocab inverso (int → str)\n",
        "        max_output_len: largo máximo de la secuencia generada\n",
        "        beam_size: cantidad de beams (1 = greedy)\n",
        "        temperature: suaviza distribución en modo estocástico\n",
        "        stochastic: si True, elige tokens por muestreo en vez de argmax\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # --- 1️⃣ Codificación ---\n",
        "        input_tensor = torch.tensor([input_seq], dtype=torch.long).to(device)\n",
        "        encoder_hidden, encoder_cell = model.encoder(input_tensor)\n",
        "\n",
        "        sos_token = word2idx_output.get(\"<sos>\", 1)\n",
        "        eos_token = word2idx_output.get(\"<eos>\", 2)\n",
        "\n",
        "        # --- 2️⃣ Inicialización de beams ---\n",
        "        beams = [{\n",
        "            \"tokens\": [sos_token],\n",
        "            \"hidden\": encoder_hidden,\n",
        "            \"cell\": encoder_cell,\n",
        "            \"logprob\": 0.0\n",
        "        }]\n",
        "\n",
        "        # --- 3️⃣ Decodificación autoregresiva ---\n",
        "        for _ in range(max_output_len):\n",
        "            new_beams = []\n",
        "            for beam in beams:\n",
        "                last_token = beam[\"tokens\"][-1]\n",
        "                if last_token == eos_token:\n",
        "                    new_beams.append(beam)\n",
        "                    continue\n",
        "\n",
        "                decoder_input = torch.tensor([[last_token]], dtype=torch.long).to(device)\n",
        "                output, (h, c) = model.decoder(decoder_input, (beam[\"hidden\"], beam[\"cell\"]))\n",
        "\n",
        "                # logits → probabilidades\n",
        "                probs = torch.softmax(output.squeeze(0) / temperature, dim=-1).cpu().numpy()\n",
        "\n",
        "                if stochastic:\n",
        "                    # muestreo aleatorio ponderado por softmax\n",
        "                    top_indices = np.random.choice(len(probs), beam_size, p=probs / probs.sum())\n",
        "                else:\n",
        "                    # top-k determinístico\n",
        "                    top_indices = probs.argsort()[-beam_size:][::-1]\n",
        "\n",
        "                for idx in top_indices:\n",
        "                    new_beams.append({\n",
        "                        \"tokens\": beam[\"tokens\"] + [idx],\n",
        "                        \"hidden\": h,\n",
        "                        \"cell\": c,\n",
        "                        \"logprob\": beam[\"logprob\"] + np.log(probs[idx] + 1e-10)\n",
        "                    })\n",
        "\n",
        "            # mantener los mejores beams según logprob promedio\n",
        "            beams = sorted(new_beams, key=lambda b: b[\"logprob\"] / len(b[\"tokens\"]), reverse=True)[:beam_size]\n",
        "\n",
        "        # --- 4️⃣ Seleccionar mejor secuencia ---\n",
        "        best_beam = max(beams, key=lambda b: b[\"logprob\"] / len(b[\"tokens\"]))\n",
        "        decoded_tokens = [\n",
        "            tok for tok in best_beam[\"tokens\"]\n",
        "            if tok not in [sos_token, eos_token]\n",
        "        ]\n",
        "\n",
        "        # --- 5️⃣ Decodificar texto ---\n",
        "        decoded_sentence = \" \".join([idx2word_output.get(tok, \"<unk>\") for tok in decoded_tokens])\n",
        "\n",
        "    return decoded_sentence, [b[\"tokens\"] for b in beams]  # devuelve también todos los beams\n"
      ],
      "metadata": {
        "id": "P80VW4vTrWMQ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(sentence, tokenizer, max_len):\n",
        "    # limpiar y convertir a índices usando el tokenizer\n",
        "    seq = tokenizer.texts_to_sequences([sentence.lower().strip()])[0]\n",
        "\n",
        "    # aplicar padding pre para que tenga longitud fija igual a la del entrenamiento\n",
        "    if len(seq) < max_len:\n",
        "        seq = [0] * (max_len - len(seq)) + seq\n",
        "    else:\n",
        "        seq = seq[-max_len:]\n",
        "\n",
        "    return seq\n"
      ],
      "metadata": {
        "id": "xefNxladr6Yt"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_sequences[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXv-bLgh0Pel",
        "outputId": "064c544f-8e22-42bb-8d03-c3c7eef87b6e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800, 1800,\n",
              "        1800, 1800,    1,   14,  320,  116])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K6XCDxHO0g_4",
        "outputId": "9443c44b-db23-4e86-abd4-897c95a1f45d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i love disney movies '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### Modelo con embeddings entrenables"
      ],
      "metadata": {
        "id": "IxbCkX6q-wTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"i love disney movies \"\n",
        "input_seq = encode_sentence(question, input_tokenizer, max_input_len)\n",
        "\n",
        "generated_answer, beams = infer(\n",
        "    model,\n",
        "    input_seq=input_seq,\n",
        "    word2idx_output=word2idx_outputs,\n",
        "    idx2word_output=idx2word_outputs,\n",
        "    beam_size=5,\n",
        "    temperature=0.8,\n",
        "    stochastic=True,   # False para beam search determinístico\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(f\"Q: {question}\")\n",
        "print(f\"A: {generated_answer}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4_IJi-jrWJ7",
        "outputId": "e5d9debb-5e6d-432e-fc3a-a3002b969376"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: i love disney movies \n",
            "A: movies movies movies movies movies yaa movie freeze and you old are you do you have any pets pets pets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### Modelo con embeddings freezados"
      ],
      "metadata": {
        "id": "QHZ5WOcx-yry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"i love disney movies \"\n",
        "input_seq = encode_sentence(question, input_tokenizer, max_input_len)\n",
        "\n",
        "generated_answer, beams = infer(\n",
        "    model_freezed,\n",
        "    input_seq=input_seq,\n",
        "    word2idx_output=word2idx_outputs,\n",
        "    idx2word_output=idx2word_outputs,\n",
        "    beam_size=5,\n",
        "    temperature=0.8,\n",
        "    stochastic=True,   # False para beam search determinístico\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(f\"Q: {question}\")\n",
        "print(f\"A: {generated_answer}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKU7zAEm-3IX",
        "outputId": "29abd4b3-fc37-4489-cfc3-da664f6a707e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: i love disney movies \n",
            "A: k winter u lawyer noumber rolling most mostly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkOjSJweqdF8"
      },
      "source": [
        "### 6 - Conclusión\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rualuy2NrXDW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}