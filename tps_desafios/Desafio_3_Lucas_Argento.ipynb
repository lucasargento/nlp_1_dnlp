{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## **Desafio 3: Modelo de lenguaje con tokenizaci√≥n por caracteres**\n",
        "\n",
        "### Lucas Argento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validaci√≥n.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determ√≠stico y estoc√°stico. En este √∫ltimo caso observar el efecto de la temperatura en la generaci√≥n de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validaci√≥n para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "## 0. Datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7amy6uUaBLVD"
      },
      "outputs": [],
      "source": [
        "# descargar de textos.info\n",
        "import urllib.request\n",
        "\n",
        "# Para leer y parsear el texto en HTML de wikipedia\n",
        "import bs4 as bs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "book = \"https://www.gutenberg.org/ebooks/11.txt.utf-8\""
      ],
      "metadata": {
        "id": "Xv6CQoJT_R9R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6v_ickFwBJTy"
      },
      "outputs": [],
      "source": [
        "raw_html = urllib.request.urlopen(book)\n",
        "raw_html = raw_html.read()\n",
        "\n",
        "# Parsear art√≠culo, 'lxml' es el parser a utilizar\n",
        "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "\n",
        "# Encontrar todos los p√°rrafos del HTML (bajo el tag <p>)\n",
        "# y tenerlos disponible como lista\n",
        "article_paragraphs = article_html.find_all('p')\n",
        "\n",
        "article_text = ''\n",
        "\n",
        "for para in article_paragraphs:\n",
        "    article_text += para.text + ' '\n",
        "\n",
        "# pasar todo el texto a min√∫scula\n",
        "article_text = article_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WBE0sSYuB-E6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "19f08974-76fe-4704-b990-4cb222e1c41c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"the project gutenberg ebook of alice's adventures in wonderland\\r\\n    \\r\\nthis ebook is for the use of anyone anywhere in the united states and\\r\\nmost other parts of the world at no cost and with almost no restrictions\\r\\nwhatsoever. you may copy it, give it away or re-use it under the terms\\r\\nof the project gutenberg license included with this ebook or online\\r\\nat www.gutenberg.org. if you are not located in the united states,\\r\\nyou will have to check the laws of the country where you are located\\r\\nbefore using this ebook.\\r\\n\\r\\ntitle: alice's adventures in wonderland\\r\\n\\r\\nauthor: lewis carroll\\r\\n\\r\\nrelease date: june 27, 2008 [ebook #11]\\r\\n                most recently updated: june 26, 2025\\r\\n\\r\\nlanguage: english\\r\\n\\r\\ncredits: arthur dibianca and david widger\\r\\n\\r\\n\\r\\n*** start of the project gutenberg ebook alice's adventures in wonderland ***\\r\\n\\r\\n[illustration]\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nalice‚Äôs adventures in wonderland\\r\\n\\r\\nby lewis carroll\\r\\n\\r\\nthe millennium fulcrum edition 3.0\\r\\n\\r\\ncontents\\r\\n\\r\\n chapter i.     down the rabbit-h\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# en article text se encuentra el texto de todo el libro\n",
        "article_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### 0.1 Elegimos el tama√±o del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en s√≠ mismo y el tama√±o de contexto\n",
        "puede ser elegido con m√°s libertad en comparaci√≥n a un modelo de lenguaje tokenizado por palabras y dividido en documentos m√°s acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tama√±o de contexto\n",
        "max_context_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizar√° para padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto √∫nico de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VwTK6xgLJd8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01a7c05-1a5b-439d-d023-7cc624a08519"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan √≠ndices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servir√° como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "### 0.2  Tokenizacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PwGVSKOiJ5bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "54027d14-c179-4dcc-adc8-d545d6b50ee8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 47,\n",
              " 31,\n",
              " 48,\n",
              " 18,\n",
              " 33,\n",
              " 59,\n",
              " 56,\n",
              " 37,\n",
              " 19,\n",
              " 2,\n",
              " 56,\n",
              " 33,\n",
              " 34,\n",
              " 14,\n",
              " 33,\n",
              " 31,\n",
              " 19,\n",
              " 37,\n",
              " 33,\n",
              " 14,\n",
              " 48,\n",
              " 48,\n",
              " 26,\n",
              " 37,\n",
              " 48,\n",
              " 39,\n",
              " 37,\n",
              " 16,\n",
              " 15,\n",
              " 57,\n",
              " 59,\n",
              " 33,\n",
              " 62,\n",
              " 6,\n",
              " 37,\n",
              " 16,\n",
              " 12,\n",
              " 54,\n",
              " 33,\n",
              " 34,\n",
              " 56,\n",
              " 2,\n",
              " 31,\n",
              " 33,\n",
              " 6,\n",
              " 37,\n",
              " 57,\n",
              " 34,\n",
              " 37,\n",
              " 25,\n",
              " 48,\n",
              " 34,\n",
              " 12,\n",
              " 33,\n",
              " 31,\n",
              " 15,\n",
              " 16,\n",
              " 34,\n",
              " 12,\n",
              " 38,\n",
              " 60,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 38,\n",
              " 60,\n",
              " 56,\n",
              " 1,\n",
              " 57,\n",
              " 6,\n",
              " 37,\n",
              " 33,\n",
              " 14,\n",
              " 48,\n",
              " 48,\n",
              " 26,\n",
              " 37,\n",
              " 57,\n",
              " 6,\n",
              " 37,\n",
              " 39,\n",
              " 48,\n",
              " 31,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 2,\n",
              " 6,\n",
              " 33,\n",
              " 37,\n",
              " 48,\n",
              " 39,\n",
              " 37,\n",
              " 16,\n",
              " 34,\n",
              " 0,\n",
              " 48,\n",
              " 34,\n",
              " 33,\n",
              " 37,\n",
              " 16,\n",
              " 34,\n",
              " 0,\n",
              " 25,\n",
              " 1,\n",
              " 33,\n",
              " 31,\n",
              " 33,\n",
              " 37,\n",
              " 57,\n",
              " 34,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 2,\n",
              " 34,\n",
              " 57,\n",
              " 56,\n",
              " 33,\n",
              " 12,\n",
              " 37,\n",
              " 6,\n",
              " 56,\n",
              " 16,\n",
              " 56,\n",
              " 33,\n",
              " 6,\n",
              " 37,\n",
              " 16,\n",
              " 34,\n",
              " 12,\n",
              " 38,\n",
              " 60,\n",
              " 17,\n",
              " 48,\n",
              " 6,\n",
              " 56,\n",
              " 37,\n",
              " 48,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 31,\n",
              " 37,\n",
              " 47,\n",
              " 16,\n",
              " 31,\n",
              " 56,\n",
              " 6,\n",
              " 37,\n",
              " 48,\n",
              " 39,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 25,\n",
              " 48,\n",
              " 31,\n",
              " 15,\n",
              " 12,\n",
              " 37,\n",
              " 16,\n",
              " 56,\n",
              " 37,\n",
              " 34,\n",
              " 48,\n",
              " 37,\n",
              " 59,\n",
              " 48,\n",
              " 6,\n",
              " 56,\n",
              " 37,\n",
              " 16,\n",
              " 34,\n",
              " 12,\n",
              " 37,\n",
              " 25,\n",
              " 57,\n",
              " 56,\n",
              " 1,\n",
              " 37,\n",
              " 16,\n",
              " 15,\n",
              " 17,\n",
              " 48,\n",
              " 6,\n",
              " 56,\n",
              " 37,\n",
              " 34,\n",
              " 48,\n",
              " 37,\n",
              " 31,\n",
              " 33,\n",
              " 6,\n",
              " 56,\n",
              " 31,\n",
              " 57,\n",
              " 59,\n",
              " 56,\n",
              " 57,\n",
              " 48,\n",
              " 34,\n",
              " 6,\n",
              " 38,\n",
              " 60,\n",
              " 25,\n",
              " 1,\n",
              " 16,\n",
              " 56,\n",
              " 6,\n",
              " 48,\n",
              " 33,\n",
              " 54,\n",
              " 33,\n",
              " 31,\n",
              " 20,\n",
              " 37,\n",
              " 0,\n",
              " 48,\n",
              " 2,\n",
              " 37,\n",
              " 17,\n",
              " 16,\n",
              " 0,\n",
              " 37,\n",
              " 59,\n",
              " 48,\n",
              " 47,\n",
              " 0,\n",
              " 37,\n",
              " 57,\n",
              " 56,\n",
              " 28,\n",
              " 37,\n",
              " 19,\n",
              " 57,\n",
              " 54,\n",
              " 33,\n",
              " 37,\n",
              " 57,\n",
              " 56,\n",
              " 37,\n",
              " 16,\n",
              " 25,\n",
              " 16,\n",
              " 0,\n",
              " 37,\n",
              " 48,\n",
              " 31,\n",
              " 37,\n",
              " 31,\n",
              " 33,\n",
              " 40,\n",
              " 2,\n",
              " 6,\n",
              " 33,\n",
              " 37,\n",
              " 57,\n",
              " 56,\n",
              " 37,\n",
              " 2,\n",
              " 34,\n",
              " 12,\n",
              " 33,\n",
              " 31,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 56,\n",
              " 33,\n",
              " 31,\n",
              " 17,\n",
              " 6,\n",
              " 38,\n",
              " 60,\n",
              " 48,\n",
              " 39,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 47,\n",
              " 31,\n",
              " 48,\n",
              " 18,\n",
              " 33,\n",
              " 59,\n",
              " 56,\n",
              " 37,\n",
              " 19,\n",
              " 2,\n",
              " 56,\n",
              " 33,\n",
              " 34,\n",
              " 14,\n",
              " 33,\n",
              " 31,\n",
              " 19,\n",
              " 37,\n",
              " 15,\n",
              " 57,\n",
              " 59,\n",
              " 33,\n",
              " 34,\n",
              " 6,\n",
              " 33,\n",
              " 37,\n",
              " 57,\n",
              " 34,\n",
              " 59,\n",
              " 15,\n",
              " 2,\n",
              " 12,\n",
              " 33,\n",
              " 12,\n",
              " 37,\n",
              " 25,\n",
              " 57,\n",
              " 56,\n",
              " 1,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 57,\n",
              " 6,\n",
              " 37,\n",
              " 33,\n",
              " 14,\n",
              " 48,\n",
              " 48,\n",
              " 26,\n",
              " 37,\n",
              " 48,\n",
              " 31,\n",
              " 37,\n",
              " 48,\n",
              " 34,\n",
              " 15,\n",
              " 57,\n",
              " 34,\n",
              " 33,\n",
              " 38,\n",
              " 60,\n",
              " 16,\n",
              " 56,\n",
              " 37,\n",
              " 25,\n",
              " 25,\n",
              " 25,\n",
              " 20,\n",
              " 19,\n",
              " 2,\n",
              " 56,\n",
              " 33,\n",
              " 34,\n",
              " 14,\n",
              " 33,\n",
              " 31,\n",
              " 19,\n",
              " 20,\n",
              " 48,\n",
              " 31,\n",
              " 19,\n",
              " 20,\n",
              " 37,\n",
              " 57,\n",
              " 39,\n",
              " 37,\n",
              " 0,\n",
              " 48,\n",
              " 2,\n",
              " 37,\n",
              " 16,\n",
              " 31,\n",
              " 33,\n",
              " 37,\n",
              " 34,\n",
              " 48,\n",
              " 56,\n",
              " 37,\n",
              " 15,\n",
              " 48,\n",
              " 59,\n",
              " 16,\n",
              " 56,\n",
              " 33,\n",
              " 12,\n",
              " 37,\n",
              " 57,\n",
              " 34,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 2,\n",
              " 34,\n",
              " 57,\n",
              " 56,\n",
              " 33,\n",
              " 12,\n",
              " 37,\n",
              " 6,\n",
              " 56,\n",
              " 16,\n",
              " 56,\n",
              " 33,\n",
              " 6,\n",
              " 28,\n",
              " 38,\n",
              " 60,\n",
              " 0,\n",
              " 48,\n",
              " 2,\n",
              " 37,\n",
              " 25,\n",
              " 57,\n",
              " 15,\n",
              " 15,\n",
              " 37,\n",
              " 1,\n",
              " 16,\n",
              " 54,\n",
              " 33,\n",
              " 37,\n",
              " 56,\n",
              " 48,\n",
              " 37,\n",
              " 59,\n",
              " 1,\n",
              " 33,\n",
              " 59,\n",
              " 26,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 15,\n",
              " 16,\n",
              " 25,\n",
              " 6,\n",
              " 37,\n",
              " 48,\n",
              " 39,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 59,\n",
              " 48,\n",
              " 2,\n",
              " 34,\n",
              " 56,\n",
              " 31,\n",
              " 0,\n",
              " 37,\n",
              " 25,\n",
              " 1,\n",
              " 33,\n",
              " 31,\n",
              " 33,\n",
              " 37,\n",
              " 0,\n",
              " 48,\n",
              " 2,\n",
              " 37,\n",
              " 16,\n",
              " 31,\n",
              " 33,\n",
              " 37,\n",
              " 15,\n",
              " 48,\n",
              " 59,\n",
              " 16,\n",
              " 56,\n",
              " 33,\n",
              " 12,\n",
              " 38,\n",
              " 60,\n",
              " 14,\n",
              " 33,\n",
              " 39,\n",
              " 48,\n",
              " 31,\n",
              " 33,\n",
              " 37,\n",
              " 2,\n",
              " 6,\n",
              " 57,\n",
              " 34,\n",
              " 19,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 57,\n",
              " 6,\n",
              " 37,\n",
              " 33,\n",
              " 14,\n",
              " 48,\n",
              " 48,\n",
              " 26,\n",
              " 20,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 56,\n",
              " 57,\n",
              " 56,\n",
              " 15,\n",
              " 33,\n",
              " 24,\n",
              " 37,\n",
              " 16,\n",
              " 15,\n",
              " 57,\n",
              " 59,\n",
              " 33,\n",
              " 62,\n",
              " 6,\n",
              " 37,\n",
              " 16,\n",
              " 12,\n",
              " 54,\n",
              " 33,\n",
              " 34,\n",
              " 56,\n",
              " 2,\n",
              " 31,\n",
              " 33,\n",
              " 6,\n",
              " 37,\n",
              " 57,\n",
              " 34,\n",
              " 37,\n",
              " 25,\n",
              " 48,\n",
              " 34,\n",
              " 12,\n",
              " 33,\n",
              " 31,\n",
              " 15,\n",
              " 16,\n",
              " 34,\n",
              " 12,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 16,\n",
              " 2,\n",
              " 56,\n",
              " 1,\n",
              " 48,\n",
              " 31,\n",
              " 24,\n",
              " 37,\n",
              " 15,\n",
              " 33,\n",
              " 25,\n",
              " 57,\n",
              " 6,\n",
              " 37,\n",
              " 59,\n",
              " 16,\n",
              " 31,\n",
              " 31,\n",
              " 48,\n",
              " 15,\n",
              " 15,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 31,\n",
              " 33,\n",
              " 15,\n",
              " 33,\n",
              " 16,\n",
              " 6,\n",
              " 33,\n",
              " 37,\n",
              " 12,\n",
              " 16,\n",
              " 56,\n",
              " 33,\n",
              " 24,\n",
              " 37,\n",
              " 18,\n",
              " 2,\n",
              " 34,\n",
              " 33,\n",
              " 37,\n",
              " 11,\n",
              " 44,\n",
              " 28,\n",
              " 37,\n",
              " 11,\n",
              " 49,\n",
              " 49,\n",
              " 5,\n",
              " 37,\n",
              " 3,\n",
              " 33,\n",
              " 14,\n",
              " 48,\n",
              " 48,\n",
              " 26,\n",
              " 37,\n",
              " 32,\n",
              " 53,\n",
              " 53,\n",
              " 9,\n",
              " 38,\n",
              " 60,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 17,\n",
              " 48,\n",
              " 6,\n",
              " 56,\n",
              " 37,\n",
              " 31,\n",
              " 33,\n",
              " 59,\n",
              " 33,\n",
              " 34,\n",
              " 56,\n",
              " 15,\n",
              " 0,\n",
              " 37,\n",
              " 2,\n",
              " 47,\n",
              " 12,\n",
              " 16,\n",
              " 56,\n",
              " 33,\n",
              " 12,\n",
              " 24,\n",
              " 37,\n",
              " 18,\n",
              " 2,\n",
              " 34,\n",
              " 33,\n",
              " 37,\n",
              " 11,\n",
              " 51,\n",
              " 28,\n",
              " 37,\n",
              " 11,\n",
              " 49,\n",
              " 11,\n",
              " 4,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 15,\n",
              " 16,\n",
              " 34,\n",
              " 19,\n",
              " 2,\n",
              " 16,\n",
              " 19,\n",
              " 33,\n",
              " 24,\n",
              " 37,\n",
              " 33,\n",
              " 34,\n",
              " 19,\n",
              " 15,\n",
              " 57,\n",
              " 6,\n",
              " 1,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 59,\n",
              " 31,\n",
              " 33,\n",
              " 12,\n",
              " 57,\n",
              " 56,\n",
              " 6,\n",
              " 24,\n",
              " 37,\n",
              " 16,\n",
              " 31,\n",
              " 56,\n",
              " 1,\n",
              " 2,\n",
              " 31,\n",
              " 37,\n",
              " 12,\n",
              " 57,\n",
              " 14,\n",
              " 57,\n",
              " 16,\n",
              " 34,\n",
              " 59,\n",
              " 16,\n",
              " 37,\n",
              " 16,\n",
              " 34,\n",
              " 12,\n",
              " 37,\n",
              " 12,\n",
              " 16,\n",
              " 54,\n",
              " 57,\n",
              " 12,\n",
              " 37,\n",
              " 25,\n",
              " 57,\n",
              " 12,\n",
              " 19,\n",
              " 33,\n",
              " 31,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 63,\n",
              " 63,\n",
              " 63,\n",
              " 37,\n",
              " 6,\n",
              " 56,\n",
              " 16,\n",
              " 31,\n",
              " 56,\n",
              " 37,\n",
              " 48,\n",
              " 39,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 47,\n",
              " 31,\n",
              " 48,\n",
              " 18,\n",
              " 33,\n",
              " 59,\n",
              " 56,\n",
              " 37,\n",
              " 19,\n",
              " 2,\n",
              " 56,\n",
              " 33,\n",
              " 34,\n",
              " 14,\n",
              " 33,\n",
              " 31,\n",
              " 19,\n",
              " 37,\n",
              " 33,\n",
              " 14,\n",
              " 48,\n",
              " 48,\n",
              " 26,\n",
              " 37,\n",
              " 16,\n",
              " 15,\n",
              " 57,\n",
              " 59,\n",
              " 33,\n",
              " 62,\n",
              " 6,\n",
              " 37,\n",
              " 16,\n",
              " 12,\n",
              " 54,\n",
              " 33,\n",
              " 34,\n",
              " 56,\n",
              " 2,\n",
              " 31,\n",
              " 33,\n",
              " 6,\n",
              " 37,\n",
              " 57,\n",
              " 34,\n",
              " 37,\n",
              " 25,\n",
              " 48,\n",
              " 34,\n",
              " 12,\n",
              " 33,\n",
              " 31,\n",
              " 15,\n",
              " 16,\n",
              " 34,\n",
              " 12,\n",
              " 37,\n",
              " 63,\n",
              " 63,\n",
              " 63,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 3,\n",
              " 57,\n",
              " 15,\n",
              " 15,\n",
              " 2,\n",
              " 6,\n",
              " 56,\n",
              " 31,\n",
              " 16,\n",
              " 56,\n",
              " 57,\n",
              " 48,\n",
              " 34,\n",
              " 9,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 16,\n",
              " 15,\n",
              " 57,\n",
              " 59,\n",
              " 33,\n",
              " 22,\n",
              " 6,\n",
              " 37,\n",
              " 16,\n",
              " 12,\n",
              " 54,\n",
              " 33,\n",
              " 34,\n",
              " 56,\n",
              " 2,\n",
              " 31,\n",
              " 33,\n",
              " 6,\n",
              " 37,\n",
              " 57,\n",
              " 34,\n",
              " 37,\n",
              " 25,\n",
              " 48,\n",
              " 34,\n",
              " 12,\n",
              " 33,\n",
              " 31,\n",
              " 15,\n",
              " 16,\n",
              " 34,\n",
              " 12,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 14,\n",
              " 0,\n",
              " 37,\n",
              " 15,\n",
              " 33,\n",
              " 25,\n",
              " 57,\n",
              " 6,\n",
              " 37,\n",
              " 59,\n",
              " 16,\n",
              " 31,\n",
              " 31,\n",
              " 48,\n",
              " 15,\n",
              " 15,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 17,\n",
              " 57,\n",
              " 15,\n",
              " 15,\n",
              " 33,\n",
              " 34,\n",
              " 34,\n",
              " 57,\n",
              " 2,\n",
              " 17,\n",
              " 37,\n",
              " 39,\n",
              " 2,\n",
              " 15,\n",
              " 59,\n",
              " 31,\n",
              " 2,\n",
              " 17,\n",
              " 37,\n",
              " 33,\n",
              " 12,\n",
              " 57,\n",
              " 56,\n",
              " 57,\n",
              " 48,\n",
              " 34,\n",
              " 37,\n",
              " 52,\n",
              " 20,\n",
              " 49,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 59,\n",
              " 48,\n",
              " 34,\n",
              " 56,\n",
              " 33,\n",
              " 34,\n",
              " 56,\n",
              " 6,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 37,\n",
              " 59,\n",
              " 1,\n",
              " 16,\n",
              " 47,\n",
              " 56,\n",
              " 33,\n",
              " 31,\n",
              " 37,\n",
              " 57,\n",
              " 20,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 12,\n",
              " 48,\n",
              " 25,\n",
              " 34,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 31,\n",
              " 16,\n",
              " 14,\n",
              " 14,\n",
              " 57,\n",
              " 56,\n",
              " 40,\n",
              " 1]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tokenized_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### 0.3 Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "train_text = tokenized_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": [
        "N√≥tese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posici√≥n y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una se√±al de gradiente por el grafo de c√≥mputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde s√≥lo una se√±al de gradiente se propaga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validaci√≥n que utilizaremos para medir la calidad de la generaci√≥n de secuencias con la m√©trica de Perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KFAyA4zCWE-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08dd6e4-781f-4050-c9fc-0a0a6158f6a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150774, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qcKRl70HFTzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b83e64-8123-4091-e49d-5e3930509df8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([56,  1, 33, 37, 47, 31, 48, 18, 33, 59])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "X[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TVpLCKSZFXZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b56eb96b-921f-4197-ea45-b694d213ecf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1, 33, 37, 47, 31, 48, 18, 33, 59, 56])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "y[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wOFCR-KqbW1N"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(chars_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "## 1. Definiendo Los Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Definiremos 3 modelos en PyTorch para comparar su performance: celda de Elman (RNN basica), LSTM y GRU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "class PerplexityEvaluator:\n",
        "    \"\"\"\n",
        "    Eval√∫a la perplejidad promedio sobre el conjunto de validaci√≥n.\n",
        "    Usa CrossEntropyLoss directamente (coherente con el entrenamiento).\n",
        "    Incluye early stopping y guardado del mejor modelo.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X_val, y_val, model, device,\n",
        "                 patience=5, save_path=\"best_model.pt\", eval_batch_size=64):\n",
        "        \"\"\"\n",
        "        X_val, y_val: tensores o arrays numpy del conjunto de validaci√≥n\n",
        "        model: instancia del modelo PyTorch\n",
        "        device: torch.device(\"cuda\" o \"cpu\")\n",
        "        patience: epochs sin mejora antes de early stopping\n",
        "        save_path: ruta para guardar el mejor modelo\n",
        "        eval_batch_size: tama√±o de batch en validaci√≥n\n",
        "        \"\"\"\n",
        "        # convertir arrays numpy a tensores si es necesario\n",
        "        if isinstance(X_val, np.ndarray):\n",
        "            X_val = torch.tensor(X_val, dtype=torch.long)\n",
        "        if isinstance(y_val, np.ndarray):\n",
        "            y_val = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "        self.inputs = X_val\n",
        "        self.targets = y_val\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.patience = patience\n",
        "        self.save_path = save_path\n",
        "        self.eval_batch_size = eval_batch_size\n",
        "\n",
        "        self.min_score = np.inf\n",
        "        self.patience_counter = 0\n",
        "        self.history_ppl = []\n",
        "\n",
        "    def compute_perplexity(self):\n",
        "        \"\"\"Eval√∫a la perplejidad promedio en batches.\"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        total_tokens = 0\n",
        "        criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "\n",
        "        dataset = TensorDataset(self.inputs, self.targets)\n",
        "        loader = DataLoader(dataset, batch_size=self.eval_batch_size, shuffle=False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in loader:\n",
        "                X_batch = X_batch.to(self.device)\n",
        "                y_batch = y_batch.to(self.device)\n",
        "\n",
        "                try:\n",
        "                    outputs, _ = self.model(X_batch)\n",
        "                except RuntimeError as e:\n",
        "                    if \"out of memory\" in str(e).lower():\n",
        "                        print(\"‚ö†Ô∏è GPU sin memoria ‚Äî evaluando perplejidad en CPU temporalmente.\")\n",
        "                        torch.cuda.empty_cache()\n",
        "                        self.model.to(\"cpu\")\n",
        "                        X_batch = X_batch.to(\"cpu\")\n",
        "                        y_batch = y_batch.to(\"cpu\")\n",
        "                        outputs, _ = self.model(X_batch)\n",
        "                        self.model.to(self.device)\n",
        "                    else:\n",
        "                        raise e\n",
        "\n",
        "                loss = criterion(outputs.view(-1, self.model.fc.out_features),\n",
        "                                 y_batch.view(-1))\n",
        "                total_loss += loss.item()\n",
        "                total_tokens += y_batch.numel()\n",
        "\n",
        "        mean_loss = total_loss / total_tokens\n",
        "        ppl = np.exp(mean_loss)\n",
        "        return ppl\n",
        "\n",
        "    def on_epoch_end(self, epoch):\n",
        "        \"\"\"Calcula perplejidad, guarda modelo si mejora y aplica early stopping.\"\"\"\n",
        "        ppl = self.compute_perplexity()\n",
        "        self.history_ppl.append(ppl)\n",
        "        print(f\"Epoch {epoch+1} ‚Äî Mean Perplexity: {ppl:.3f}\")\n",
        "\n",
        "        if ppl < self.min_score:\n",
        "            self.min_score = ppl\n",
        "            self.patience_counter = 0\n",
        "            torch.save(self.model.state_dict(), self.save_path)\n",
        "            print(\"‚úÖ Saved new best model.\")\n",
        "        else:\n",
        "            self.patience_counter += 1\n",
        "            if self.patience_counter >= self.patience:\n",
        "                print(\"‚õî Early stopping triggered.\")\n",
        "                return True\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "f4z6E40QCmip"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 SimpleRNN"
      ],
      "metadata": {
        "id": "8JDIm4lYCOWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleRNNLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size=200, emb_dim=128, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # embedding para reemplazar one-hot\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=emb_dim)\n",
        "\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=emb_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        # x: [batch, seq_len]\n",
        "        x_emb = self.embedding(x)             # [batch, seq_len, emb_dim]\n",
        "        out, hidden = self.rnn(x_emb, hidden) # [batch, seq_len, hidden_size]\n",
        "        logits = self.fc(out)                 # [batch, seq_len, vocab_size]\n",
        "        return logits, hidden\n"
      ],
      "metadata": {
        "id": "0hRZSw3OCTFn"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 LSTM"
      ],
      "metadata": {
        "id": "wz95TINWCQjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "class LSTMLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size=200, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.LSTM(vocab_size, hidden_size, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = F.one_hot(x, num_classes=self.fc.out_features).float()\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        return self.fc(out), hidden\n"
      ],
      "metadata": {
        "id": "-BUTSIXdCStJ"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 GRU"
      ],
      "metadata": {
        "id": "dghUOgrXCTjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRULanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size=200, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.GRU(vocab_size, hidden_size, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = F.one_hot(x, num_classes=self.fc.out_features).float()\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        return self.fc(out), hidden"
      ],
      "metadata": {
        "id": "2e_H5UyEC6R7"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "## 2. Entrenamiento de los modelos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_data, device, vocab_size,\n",
        "                max_context_size,\n",
        "                n_epochs=20, lr=0.001, patience=5, model_name=\"model\"\n",
        "                ):\n",
        "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    evaluator = PerplexityEvaluator(\n",
        "        X_val, y_val,\n",
        "        model=model,\n",
        "        device=device,\n",
        "        patience=5,\n",
        "        save_path=f\"{model_name}_best.pt\",\n",
        "        eval_batch_size=32\n",
        "    )\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs, _ = model(X_batch)\n",
        "            loss = criterion(outputs.view(-1, vocab_size), y_batch.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"\\nEpoch {epoch+1}/{n_epochs} ‚Äî Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Calcular perplejidad y chequear early stopping\n",
        "        stop = evaluator.on_epoch_end(epoch)\n",
        "        if stop:\n",
        "            print(f\"Entrenamiento detenido en epoch {epoch+1} (early stopping).\")\n",
        "            break\n",
        "\n",
        "    # üîπ Guardar el modelo final (√∫ltimo epoch entrenado)\n",
        "    final_path = f\"{model_name}_final.pt\"\n",
        "    torch.save(model.state_dict(), final_path)\n",
        "    print(f\"Modelo final guardado en: {final_path}\")\n",
        "    print(f\"Mejor modelo guardado en: {model_name}_best.pt\")\n",
        "\n",
        "    return evaluator.history_ppl, model\n"
      ],
      "metadata": {
        "id": "1DfV9e_uDBNZ"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"- Vocab size: \", vocab_size)\n",
        "print(\"- Context Len:\", max_context_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5QxwXk3DKf6",
        "outputId": "81efe048-3a44-4c0d-de57-fcc7acffa30c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Vocab size:  65\n",
            "- Context Len: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "LR = 0.001\n",
        "PATIENCE = 5\n",
        "\n",
        "seq_len = max_context_size\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
        "X_val_t   = torch.tensor(X_val, dtype=torch.long)\n",
        "y_val_t   = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "val_dataset   = TensorDataset(X_val_t, y_val_t)\n",
        "\n",
        "# 4Ô∏è‚É£ DataLoaders (listas para tu loop)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "# Datos de validaci√≥n (listas de secuencias)\n",
        "val_data = [seq.tolist() for seq in X_val_t]  # compatible con tu callback\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Entrenar los tres modelos\n",
        "models = {\n",
        "    \"SimpleRNN\": SimpleRNNLanguageModel(vocab_size),\n",
        "    \"LSTM\": LSTMLanguageModel(vocab_size),\n",
        "    \"GRU\": GRULanguageModel(vocab_size)\n",
        "}\n",
        "\n",
        "history = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n- Entrenando {name}...\")\n",
        "    model.to(device)\n",
        "    history[name], model = train_model(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_data=val_data,\n",
        "        device=device,\n",
        "        vocab_size=vocab_size,\n",
        "        n_epochs=EPOCHS,\n",
        "        max_context_size=seq_len,\n",
        "        lr=LR,\n",
        "        patience=PATIENCE,\n",
        "        model_name=name,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpcgQ54GDDtD",
        "outputId": "22614aaa-0e92-4c24-c703-84050b867026"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- Entrenando SimpleRNN...\n",
            "\n",
            "Epoch 1/20 ‚Äî Loss: 1.2941\n",
            "Epoch 1 ‚Äî Mean Perplexity: 3.013\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 2/20 ‚Äî Loss: 1.0425\n",
            "Epoch 2 ‚Äî Mean Perplexity: 2.737\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 3/20 ‚Äî Loss: 0.9867\n",
            "Epoch 3 ‚Äî Mean Perplexity: 2.660\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 4/20 ‚Äî Loss: 0.9677\n",
            "Epoch 4 ‚Äî Mean Perplexity: 2.614\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 5/20 ‚Äî Loss: 0.9577\n",
            "Epoch 5 ‚Äî Mean Perplexity: 2.614\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 6/20 ‚Äî Loss: 0.9522\n",
            "Epoch 6 ‚Äî Mean Perplexity: 2.607\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 7/20 ‚Äî Loss: 0.9479\n",
            "Epoch 7 ‚Äî Mean Perplexity: 2.595\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 8/20 ‚Äî Loss: 0.9445\n",
            "Epoch 8 ‚Äî Mean Perplexity: 2.596\n",
            "\n",
            "Epoch 9/20 ‚Äî Loss: 0.9415\n",
            "Epoch 9 ‚Äî Mean Perplexity: 2.573\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 10/20 ‚Äî Loss: 0.9390\n",
            "Epoch 10 ‚Äî Mean Perplexity: 2.572\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 11/20 ‚Äî Loss: 0.9363\n",
            "Epoch 11 ‚Äî Mean Perplexity: 2.564\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 12/20 ‚Äî Loss: 0.9348\n",
            "Epoch 12 ‚Äî Mean Perplexity: 2.547\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 13/20 ‚Äî Loss: 0.9325\n",
            "Epoch 13 ‚Äî Mean Perplexity: 2.553\n",
            "\n",
            "Epoch 14/20 ‚Äî Loss: 0.9309\n",
            "Epoch 14 ‚Äî Mean Perplexity: 2.579\n",
            "\n",
            "Epoch 15/20 ‚Äî Loss: 0.9291\n",
            "Epoch 15 ‚Äî Mean Perplexity: 2.544\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 16/20 ‚Äî Loss: 0.9275\n",
            "Epoch 16 ‚Äî Mean Perplexity: 2.549\n",
            "\n",
            "Epoch 17/20 ‚Äî Loss: 0.9262\n",
            "Epoch 17 ‚Äî Mean Perplexity: 2.536\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 18/20 ‚Äî Loss: 0.9247\n",
            "Epoch 18 ‚Äî Mean Perplexity: 2.523\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 19/20 ‚Äî Loss: 0.9233\n",
            "Epoch 19 ‚Äî Mean Perplexity: 2.537\n",
            "\n",
            "Epoch 20/20 ‚Äî Loss: 0.9220\n",
            "Epoch 20 ‚Äî Mean Perplexity: 2.525\n",
            "Modelo final guardado en: SimpleRNN_final.pt\n",
            "Mejor modelo guardado en: SimpleRNN_best.pt\n",
            "\n",
            "- Entrenando LSTM...\n",
            "\n",
            "Epoch 1/20 ‚Äî Loss: 1.4316\n",
            "Epoch 1 ‚Äî Mean Perplexity: 2.707\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 2/20 ‚Äî Loss: 0.8300\n",
            "Epoch 2 ‚Äî Mean Perplexity: 2.038\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 3/20 ‚Äî Loss: 0.6499\n",
            "Epoch 3 ‚Äî Mean Perplexity: 1.824\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 4/20 ‚Äî Loss: 0.5607\n",
            "Epoch 4 ‚Äî Mean Perplexity: 1.717\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 5/20 ‚Äî Loss: 0.5067\n",
            "Epoch 5 ‚Äî Mean Perplexity: 1.637\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 6/20 ‚Äî Loss: 0.4698\n",
            "Epoch 6 ‚Äî Mean Perplexity: 1.611\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 7/20 ‚Äî Loss: 0.4424\n",
            "Epoch 7 ‚Äî Mean Perplexity: 1.571\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 8/20 ‚Äî Loss: 0.4213\n",
            "Epoch 8 ‚Äî Mean Perplexity: 1.512\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 9/20 ‚Äî Loss: 0.4043\n",
            "Epoch 9 ‚Äî Mean Perplexity: 1.491\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 10/20 ‚Äî Loss: 0.3904\n",
            "Epoch 10 ‚Äî Mean Perplexity: 1.478\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 11/20 ‚Äî Loss: 0.3787\n",
            "Epoch 11 ‚Äî Mean Perplexity: 1.464\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 12/20 ‚Äî Loss: 0.3691\n",
            "Epoch 12 ‚Äî Mean Perplexity: 1.443\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 13/20 ‚Äî Loss: 0.3607\n",
            "Epoch 13 ‚Äî Mean Perplexity: 1.435\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 14/20 ‚Äî Loss: 0.3532\n",
            "Epoch 14 ‚Äî Mean Perplexity: 1.427\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 15/20 ‚Äî Loss: 0.3467\n",
            "Epoch 15 ‚Äî Mean Perplexity: 1.426\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 16/20 ‚Äî Loss: 0.3406\n",
            "Epoch 16 ‚Äî Mean Perplexity: 1.434\n",
            "\n",
            "Epoch 17/20 ‚Äî Loss: 0.3353\n",
            "Epoch 17 ‚Äî Mean Perplexity: 1.403\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 18/20 ‚Äî Loss: 0.3304\n",
            "Epoch 18 ‚Äî Mean Perplexity: 1.390\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 19/20 ‚Äî Loss: 0.3262\n",
            "Epoch 19 ‚Äî Mean Perplexity: 1.400\n",
            "\n",
            "Epoch 20/20 ‚Äî Loss: 0.3222\n",
            "Epoch 20 ‚Äî Mean Perplexity: 1.390\n",
            "Modelo final guardado en: LSTM_final.pt\n",
            "Mejor modelo guardado en: LSTM_best.pt\n",
            "\n",
            "- Entrenando GRU...\n",
            "\n",
            "Epoch 1/20 ‚Äî Loss: 1.3400\n",
            "Epoch 1 ‚Äî Mean Perplexity: 2.577\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 2/20 ‚Äî Loss: 0.8101\n",
            "Epoch 2 ‚Äî Mean Perplexity: 2.072\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 3/20 ‚Äî Loss: 0.6823\n",
            "Epoch 3 ‚Äî Mean Perplexity: 1.915\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 4/20 ‚Äî Loss: 0.6230\n",
            "Epoch 4 ‚Äî Mean Perplexity: 1.845\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 5/20 ‚Äî Loss: 0.5860\n",
            "Epoch 5 ‚Äî Mean Perplexity: 1.786\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 6/20 ‚Äî Loss: 0.5596\n",
            "Epoch 6 ‚Äî Mean Perplexity: 1.759\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 7/20 ‚Äî Loss: 0.5397\n",
            "Epoch 7 ‚Äî Mean Perplexity: 1.725\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 8/20 ‚Äî Loss: 0.5238\n",
            "Epoch 8 ‚Äî Mean Perplexity: 1.682\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 9/20 ‚Äî Loss: 0.5107\n",
            "Epoch 9 ‚Äî Mean Perplexity: 1.678\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 10/20 ‚Äî Loss: 0.4997\n",
            "Epoch 10 ‚Äî Mean Perplexity: 1.653\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 11/20 ‚Äî Loss: 0.4903\n",
            "Epoch 11 ‚Äî Mean Perplexity: 1.632\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 12/20 ‚Äî Loss: 0.4822\n",
            "Epoch 12 ‚Äî Mean Perplexity: 1.660\n",
            "\n",
            "Epoch 13/20 ‚Äî Loss: 0.4752\n",
            "Epoch 13 ‚Äî Mean Perplexity: 1.609\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 14/20 ‚Äî Loss: 0.4688\n",
            "Epoch 14 ‚Äî Mean Perplexity: 1.609\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 15/20 ‚Äî Loss: 0.4635\n",
            "Epoch 15 ‚Äî Mean Perplexity: 1.609\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 16/20 ‚Äî Loss: 0.4585\n",
            "Epoch 16 ‚Äî Mean Perplexity: 1.586\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 17/20 ‚Äî Loss: 0.4538\n",
            "Epoch 17 ‚Äî Mean Perplexity: 1.577\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 18/20 ‚Äî Loss: 0.4497\n",
            "Epoch 18 ‚Äî Mean Perplexity: 1.580\n",
            "\n",
            "Epoch 19/20 ‚Äî Loss: 0.4455\n",
            "Epoch 19 ‚Äî Mean Perplexity: 1.569\n",
            "‚úÖ Saved new best model.\n",
            "\n",
            "Epoch 20/20 ‚Äî Loss: 0.4423\n",
            "Epoch 20 ‚Äî Mean Perplexity: 1.554\n",
            "‚úÖ Saved new best model.\n",
            "Modelo final guardado en: GRU_final.pt\n",
            "Mejor modelo guardado en: GRU_best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for name, h in history.items():\n",
        "    plt.plot(h, label=name)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Perplexity\")\n",
        "plt.legend()\n",
        "plt.title(\"Evoluci√≥n de la perplejidad por modelo\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "vz8j4gILF5hg",
        "outputId": "802d9e50-30cc-4c94-8f57-1d4b6ad50863"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "## 3. Predicci√≥n del pr√≥ximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "IBvKHFPmzpy2"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_type):\n",
        "    \"\"\"\n",
        "    Carga el modelo seleccionado desde su archivo *_best.pt.\n",
        "    \"\"\"\n",
        "    model_map = {\n",
        "        \"SimpleRNN\": SimpleRNNLanguageModel,\n",
        "        \"LSTM\": LSTMLanguageModel,\n",
        "        \"GRU\": GRULanguageModel\n",
        "    }\n",
        "    model_class = model_map[model_type]\n",
        "    model = model_class(vocab_size=len(char2idx))\n",
        "    model_path = f\"{model_type}_best.pt\"\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        print(f\"‚úÖ Modelo {model_type} cargado desde {model_path}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ö†Ô∏è No se encontr√≥ el archivo {model_path}. Asegurate de haberlo entrenado.\")\n",
        "        model = None\n",
        "    return model"
      ],
      "metadata": {
        "id": "v8zGkLrfTM6L"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequence_np(seq, maxlen, pad_value=0):\n",
        "    seq = np.array(seq)\n",
        "    if len(seq) < maxlen:\n",
        "        pad = np.full(maxlen - len(seq), pad_value)\n",
        "        return np.concatenate([pad, seq])\n",
        "    else:\n",
        "        return seq[-maxlen:]\n",
        "\n",
        "def model_response(human_text, model_type):\n",
        "    if len(human_text.strip()) == 0:\n",
        "        return \"\"\n",
        "\n",
        "    model = load_model(model_type)\n",
        "    if model is None:\n",
        "        return f\"‚ùå No se encontr√≥ el modelo {model_type}_best.pt\"\n",
        "\n",
        "    # 1Ô∏è‚É£ Codificar el texto\n",
        "    encoded = [char2idx.get(ch.lower(), 0) for ch in human_text]\n",
        "    encoded = pad_sequence_np(encoded, max_context_size)\n",
        "    encoded = torch.tensor(encoded, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    # 2Ô∏è‚É£ Inferencia\n",
        "    with torch.no_grad():\n",
        "        outputs, _ = model(encoded)\n",
        "        logits = outputs[:, -1, :]\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        y_hat = torch.argmax(probs, dim=-1).item()\n",
        "\n",
        "    # 3Ô∏è‚É£ Decodificar y devolver\n",
        "    next_char = idx2char[y_hat]\n",
        "    return human_text + next_char"
      ],
      "metadata": {
        "id": "axLUbBm2TQo_"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Ingresa texto\"),\n",
        "        gr.Radio([\"SimpleRNN\", \"LSTM\", \"GRU\"], label=\"Seleccionar modelo\", value=\"SimpleRNN\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Predicci√≥n del modelo\"),\n",
        "    title=\"üß† Generador de texto RNN/LSTM/GRU (PyTorch)\",\n",
        "    description=\"Seleccion√° el modelo y gener√° el siguiente car√°cter predicho.\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "id": "PzxCqZxATTus",
        "outputId": "c4f8dda8-2661-42e3-8375-bf03b2ffd98f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://34bfe93644808d25be.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://34bfe93644808d25be.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo SimpleRNN cargado desde SimpleRNN_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo SimpleRNN cargado desde SimpleRNN_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo LSTM cargado desde LSTM_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo GRU cargado desde GRU_best.pt\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://34bfe93644808d25be.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### 3.1 Generaci√≥n de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "    Genera texto autoregresivamente con un modelo PyTorch.\n",
        "    Args:\n",
        "        model (torch.nn.Module): modelo entrenado (SimpleRNN, LSTM o GRU)\n",
        "        seed_text (str): texto de entrada (contexto inicial)\n",
        "        max_length (int): longitud m√°xima de la secuencia de entrada (contexto)\n",
        "        n_words (int): cantidad de caracteres a generar\n",
        "    Returns:\n",
        "        str: texto generado (semilla + predicciones)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    output_text = seed_text\n",
        "\n",
        "    for _ in range(n_words):\n",
        "        # 1Ô∏è‚É£ Encodear texto actual\n",
        "        encoded = [char2idx.get(ch.lower(), 0) for ch in output_text]\n",
        "        if len(encoded) < max_length:\n",
        "            pad = [0] * (max_length - len(encoded))\n",
        "            encoded = pad + encoded\n",
        "        else:\n",
        "            encoded = encoded[-max_length:]\n",
        "\n",
        "        # Convertir a tensor\n",
        "        x = torch.tensor(encoded, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "        # 2Ô∏è‚É£ Forward pass\n",
        "        with torch.no_grad():\n",
        "            outputs, _ = model(x)\n",
        "            logits = outputs[:, -1, :]  # solo el √∫ltimo paso temporal\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            y_hat = torch.argmax(probs, dim=-1).item()\n",
        "\n",
        "        # 3Ô∏è‚É£ Decodificar y agregar car√°cter\n",
        "        out_char = idx2char[y_hat]\n",
        "        output_text += out_char\n",
        "\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "JoFqRC5pxzqS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e104149-4806-4f4c-9233-5d799ec88890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://3a0951aa0e6dfc9649.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3a0951aa0e6dfc9649.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo SimpleRNN cargado desde SimpleRNN_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo LSTM cargado desde LSTM_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo GRU cargado desde GRU_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo GRU cargado desde GRU_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo LSTM cargado desde LSTM_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo SimpleRNN cargado desde SimpleRNN_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo SimpleRNN cargado desde SimpleRNN_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo LSTM cargado desde LSTM_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo GRU cargado desde GRU_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo GRU cargado desde GRU_best.pt\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://3a0951aa0e6dfc9649.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "def model_response(seed_text, model_type, n_chars):\n",
        "    model = load_model(model_type)\n",
        "    generated = generate_seq(model, seed_text, max_context_size, int(n_chars))\n",
        "    return generated\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Texto inicial (semilla)\", placeholder=\"Escrib√≠ un inicio...\"),\n",
        "        gr.Radio([\"SimpleRNN\", \"LSTM\", \"GRU\"], label=\"Seleccionar modelo\", value=\"SimpleRNN\"),\n",
        "        gr.Slider(1, 200, value=50, step=1, label=\"Cantidad de caracteres a generar\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Texto generado\"),\n",
        "    title=\"üß† Generador de texto con RNN / LSTM / GRU (PyTorch)\",\n",
        "    description=\"Seleccion√° un modelo y gener√° texto autoregresivamente.\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **An√°lisis:** Notamos que en todos los casos (los 3 modelos) se refleja informacion aprendida del libro utilizado como dataset (alice in wonderland), pero no se generan oraciones ni palabras coherentes!"
      ],
      "metadata": {
        "id": "x0ZbzJ0aXt5i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  3.2 Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# ENCODE / DECODE\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def encode(text, max_length=max_context_size):\n",
        "    \"\"\"Codifica texto en tensores PyTorch con padding previo.\"\"\"\n",
        "    encoded = [char2idx.get(ch, 0) for ch in text.lower()]\n",
        "    if len(encoded) < max_length:\n",
        "        pad = [0] * (max_length - len(encoded))\n",
        "        encoded = pad + encoded\n",
        "    else:\n",
        "        encoded = encoded[-max_length:]\n",
        "    x = torch.tensor(encoded, dtype=torch.long).unsqueeze(0).to(device)\n",
        "    return x\n",
        "\n",
        "def decode(seq):\n",
        "    \"\"\"Convierte una secuencia de √≠ndices en texto.\"\"\"\n",
        "    return ''.join([idx2char[i] for i in seq])\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# SELECT CANDIDATES\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def select_candidates(preds, num_beams, vocab_size, history_probs, history_tokens, temp, mode):\n",
        "    \"\"\"\n",
        "    Selecciona los mejores candidatos del beam actual.\n",
        "    preds: lista de arrays (num_beams √ó vocab_size)\n",
        "    \"\"\"\n",
        "    pred_large = []\n",
        "\n",
        "    for idx, pp in enumerate(preds):\n",
        "        pred_large.extend(np.log(pp + 1e-10) + history_probs[idx])\n",
        "\n",
        "    pred_large = np.array(pred_large)\n",
        "\n",
        "    # Criterio de selecci√≥n\n",
        "    if mode == 'det':\n",
        "        idx_select = np.argsort(pred_large)[::-1][:num_beams]\n",
        "    elif mode == 'sto':\n",
        "        idx_select = np.random.choice(\n",
        "            np.arange(pred_large.shape[0]),\n",
        "            num_beams,\n",
        "            p=softmax(pred_large / temp)\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Wrong selection mode '{mode}'. Use 'det' or 'sto'.\")\n",
        "\n",
        "    # Indices reales\n",
        "    new_history_tokens = np.concatenate(\n",
        "        (np.array(history_tokens)[idx_select // vocab_size],\n",
        "         np.array([idx_select % vocab_size]).T),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# BEAM SEARCH (PyTorch version)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def beam_search(model, num_beams, num_words, input_text, temp=1, mode='det'):\n",
        "    \"\"\"\n",
        "    Implementaci√≥n de beam search usando un modelo PyTorch.\n",
        "    Devuelve TODAS las secuencias generadas + la mejor.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # 1Ô∏è‚É£ Primera iteraci√≥n\n",
        "    encoded = encode(input_text)\n",
        "    with torch.no_grad():\n",
        "        outputs, _ = model(encoded)\n",
        "        y_hat = torch.softmax(outputs[:, -1, :], dim=-1).cpu().numpy()[0]\n",
        "\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # Inicializaci√≥n\n",
        "    history_probs = np.zeros(num_beams)\n",
        "    history_tokens = [encoded.cpu().numpy()[0]] * num_beams\n",
        "\n",
        "    # Selecci√≥n inicial\n",
        "    history_probs, history_tokens = select_candidates(\n",
        "        [y_hat], num_beams, vocab_size,\n",
        "        history_probs, history_tokens, temp, mode\n",
        "    )\n",
        "\n",
        "    # 2Ô∏è‚É£ Loop de b√∫squeda\n",
        "    for _ in range(num_words - 1):\n",
        "        preds = []\n",
        "        for hist in history_tokens:\n",
        "            input_update = torch.tensor([hist[-max_context_size:]], dtype=torch.long).to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs, _ = model(input_update)\n",
        "                y_hat = torch.softmax(outputs[:, -1, :], dim=-1).cpu().numpy()[0]\n",
        "            preds.append(y_hat)\n",
        "\n",
        "        history_probs, history_tokens = select_candidates(\n",
        "            preds, num_beams, vocab_size,\n",
        "            history_probs, history_tokens, temp, mode\n",
        "        )\n",
        "\n",
        "    # 3Ô∏è‚É£ Ranking final\n",
        "    ranked_indices = np.argsort(history_probs)[::-1]\n",
        "    ranked_probs = history_probs[ranked_indices]\n",
        "    ranked_tokens = history_tokens[ranked_indices]\n",
        "\n",
        "    # 4Ô∏è‚É£ Decodificaci√≥n\n",
        "    decoded_sequences = [\n",
        "        decode(seq[-(len(input_text) + num_words):]) for seq in ranked_tokens\n",
        "    ]\n",
        "\n",
        "    # 5Ô∏è‚É£ Empaquetado de resultados\n",
        "    results = [\n",
        "        {\"rank\": i + 1,\n",
        "         \"log_prob\": float(ranked_probs[i]),\n",
        "         \"text\": decoded_sequences[i]}\n",
        "        for i in range(len(decoded_sequences))\n",
        "    ]\n",
        "\n",
        "    best_seq = decoded_sequences[0]\n",
        "    return best_seq, results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "GeLqAoOYW1Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b80559-39ce-468d-8459-610557f16088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÜ Mejor beam:\n",
            "alice curiosion of the project gutenberg‚Ñ¢ trademark. con\n",
            "\n",
            "üîç Otros candidatos:\n",
            "[1] logP=-7.69 ‚Üí alice curiosion of the project gutenberg‚Ñ¢ trademark. con\n",
            "[2] logP=-8.35 ‚Üí alice curiosion of the project gutenberg‚Ñ¢ trademark, and\n",
            "[3] logP=-8.96 ‚Üí alice curiosion of the project\r\n",
            "gutenberg‚Ñ¢ trademark, an\n",
            "[4] logP=-9.33 ‚Üí alice curiosion of the project\r\n",
            "gutenberg‚Ñ¢ trademark. co\n",
            "[5] logP=-10.85 ‚Üí alice curiosion of the project gutenberg‚Ñ¢ trademark. cun\n"
          ]
        }
      ],
      "source": [
        "# Texto semilla\n",
        "seed = \"Alice \"\n",
        "\n",
        "# Beam search determinista\n",
        "best, beams = beam_search(model, num_beams=5, num_words=50, input_text=seed, mode=\"det\")\n",
        "\n",
        "print(\"üèÜ Mejor beam:\")\n",
        "print(best)\n",
        "\n",
        "print(\"\\nüîç Otros candidatos:\")\n",
        "for b in beams:\n",
        "    print(f\"[{b['rank']}] logP={b['log_prob']:.2f} ‚Üí {b['text']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto semilla\n",
        "seed = \"Alice\"\n",
        "\n",
        "# Beam search determinista\n",
        "best, beams = beam_search(model, num_beams=5, num_words=50, input_text=seed, mode=\"sto\")\n",
        "\n",
        "print(\"üèÜ Mejor beam:\")\n",
        "print(best)\n",
        "\n",
        "print(\"\\nüîç Otros candidatos:\")\n",
        "for b in beams:\n",
        "    print(f\"[{b['rank']}] logP={b['log_prob']:.2f} ‚Üí {b['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9jIx5ouYFq8",
        "outputId": "3a2cc6a8-0f7d-4946-d3c3-1d673172b160"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÜ Mejor beam:\n",
            "aliced,‚Äù said the king.\r\n",
            "\r\n",
            "here one of the project gute\n",
            "\n",
            "üîç Otros candidatos:\n",
            "[1] logP=-8.42 ‚Üí aliced,‚Äù said the king.\r\n",
            "\r\n",
            "here one of the project gute\n",
            "[2] logP=-8.42 ‚Üí aliced,‚Äù said the king.\r\n",
            "\r\n",
            "here one of the project gute\n",
            "[3] logP=-8.42 ‚Üí aliced,‚Äù said the king.\r\n",
            "\r\n",
            "here one of the project gute\n",
            "[4] logP=-8.42 ‚Üí aliced,‚Äù said the king.\r\n",
            "\r\n",
            "here one of the project gute\n",
            "[5] logP=-8.42 ‚Üí aliced,‚Äù said the king.\r\n",
            "\r\n",
            "here one of the project gute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1UNHQEeYGE5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "desafios nlp 1",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}