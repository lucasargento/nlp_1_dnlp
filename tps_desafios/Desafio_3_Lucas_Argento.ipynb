{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## **Desafio 3: Modelo de lenguaje con tokenización por caracteres**\n",
        "\n",
        "### Lucas Argento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "## 0. Datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7amy6uUaBLVD"
      },
      "outputs": [],
      "source": [
        "# descargar de textos.info\n",
        "import urllib.request\n",
        "\n",
        "# Para leer y parsear el texto en HTML de wikipedia\n",
        "import bs4 as bs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "book = \"https://www.gutenberg.org/ebooks/11.txt.utf-8\""
      ],
      "metadata": {
        "id": "Xv6CQoJT_R9R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6v_ickFwBJTy"
      },
      "outputs": [],
      "source": [
        "raw_html = urllib.request.urlopen(book)\n",
        "raw_html = raw_html.read()\n",
        "\n",
        "# Parsear artículo, 'lxml' es el parser a utilizar\n",
        "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "\n",
        "# Encontrar todos los párrafos del HTML (bajo el tag <p>)\n",
        "# y tenerlos disponible como lista\n",
        "article_paragraphs = article_html.find_all('p')\n",
        "\n",
        "article_text = ''\n",
        "\n",
        "for para in article_paragraphs:\n",
        "    article_text += para.text + ' '\n",
        "\n",
        "# pasar todo el texto a minúscula\n",
        "article_text = article_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WBE0sSYuB-E6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "19f08974-76fe-4704-b990-4cb222e1c41c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"the project gutenberg ebook of alice's adventures in wonderland\\r\\n    \\r\\nthis ebook is for the use of anyone anywhere in the united states and\\r\\nmost other parts of the world at no cost and with almost no restrictions\\r\\nwhatsoever. you may copy it, give it away or re-use it under the terms\\r\\nof the project gutenberg license included with this ebook or online\\r\\nat www.gutenberg.org. if you are not located in the united states,\\r\\nyou will have to check the laws of the country where you are located\\r\\nbefore using this ebook.\\r\\n\\r\\ntitle: alice's adventures in wonderland\\r\\n\\r\\nauthor: lewis carroll\\r\\n\\r\\nrelease date: june 27, 2008 [ebook #11]\\r\\n                most recently updated: june 26, 2025\\r\\n\\r\\nlanguage: english\\r\\n\\r\\ncredits: arthur dibianca and david widger\\r\\n\\r\\n\\r\\n*** start of the project gutenberg ebook alice's adventures in wonderland ***\\r\\n\\r\\n[illustration]\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nalice’s adventures in wonderland\\r\\n\\r\\nby lewis carroll\\r\\n\\r\\nthe millennium fulcrum edition 3.0\\r\\n\\r\\ncontents\\r\\n\\r\\n chapter i.     down the rabbit-h\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# en article text se encuentra el texto de todo el libro\n",
        "article_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### 0.1 Elegimos el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VwTK6xgLJd8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01a7c05-1a5b-439d-d023-7cc624a08519"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "### 0.2  Tokenizacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PwGVSKOiJ5bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "54027d14-c179-4dcc-adc8-d545d6b50ee8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 47,\n",
              " 31,\n",
              " 48,\n",
              " 18,\n",
              " 33,\n",
              " 59,\n",
              " 56,\n",
              " 37,\n",
              " 19,\n",
              " 2,\n",
              " 56,\n",
              " 33,\n",
              " 34,\n",
              " 14,\n",
              " 33,\n",
              " 31,\n",
              " 19,\n",
              " 37,\n",
              " 33,\n",
              " 14,\n",
              " 48,\n",
              " 48,\n",
              " 26,\n",
              " 37,\n",
              " 48,\n",
              " 39,\n",
              " 37,\n",
              " 16,\n",
              " 15,\n",
              " 57,\n",
              " 59,\n",
              " 33,\n",
              " 62,\n",
              " 6,\n",
              " 37,\n",
              " 16,\n",
              " 12,\n",
              " 54,\n",
              " 33,\n",
              " 34,\n",
              " 56,\n",
              " 2,\n",
              " 31,\n",
              " 33,\n",
              " 6,\n",
              " 37,\n",
              " 57,\n",
              " 34,\n",
              " 37,\n",
              " 25,\n",
              " 48,\n",
              " 34,\n",
              " 12,\n",
              " 33,\n",
              " 31,\n",
              " 15,\n",
              " 16,\n",
              " 34,\n",
              " 12,\n",
              " 38,\n",
              " 60,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 38,\n",
              " 60,\n",
              " 56,\n",
              " 1,\n",
              " 57,\n",
              " 6,\n",
              " 37,\n",
              " 33,\n",
              " 14,\n",
              " 48,\n",
              " 48,\n",
              " 26,\n",
              " 37,\n",
              " 57,\n",
              " 6,\n",
              " 37,\n",
              " 39,\n",
              " 48,\n",
              " 31,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 2,\n",
              " 6,\n",
              " 33,\n",
              " 37,\n",
              " 48,\n",
              " 39,\n",
              " 37,\n",
              " 16,\n",
              " 34,\n",
              " 0,\n",
              " 48,\n",
              " 34,\n",
              " 33,\n",
              " 37,\n",
              " 16,\n",
              " 34,\n",
              " 0,\n",
              " 25,\n",
              " 1,\n",
              " 33,\n",
              " 31,\n",
              " 33,\n",
              " 37,\n",
              " 57,\n",
              " 34,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 2,\n",
              " 34,\n",
              " 57,\n",
              " 56,\n",
              " 33,\n",
              " 12,\n",
              " 37,\n",
              " 6,\n",
              " 56,\n",
              " 16,\n",
              " 56,\n",
              " 33,\n",
              " 6,\n",
              " 37,\n",
              " 16,\n",
              " 34,\n",
              " 12,\n",
              " 38,\n",
              " 60,\n",
              " 17,\n",
              " 48,\n",
              " 6,\n",
              " 56,\n",
              " 37,\n",
              " 48,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 31,\n",
              " 37,\n",
              " 47,\n",
              " 16,\n",
              " 31,\n",
              " 56,\n",
              " 6,\n",
              " 37,\n",
              " 48,\n",
              " 39,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 25,\n",
              " 48,\n",
              " 31,\n",
              " 15,\n",
              " 12,\n",
              " 37,\n",
              " 16,\n",
              " 56,\n",
              " 37,\n",
              " 34,\n",
              " 48,\n",
              " 37,\n",
              " 59,\n",
              " 48,\n",
              " 6,\n",
              " 56,\n",
              " 37,\n",
              " 16,\n",
              " 34,\n",
              " 12,\n",
              " 37,\n",
              " 25,\n",
              " 57,\n",
              " 56,\n",
              " 1,\n",
              " 37,\n",
              " 16,\n",
              " 15,\n",
              " 17,\n",
              " 48,\n",
              " 6,\n",
              " 56,\n",
              " 37,\n",
              " 34,\n",
              " 48,\n",
              " 37,\n",
              " 31,\n",
              " 33,\n",
              " 6,\n",
              " 56,\n",
              " 31,\n",
              " 57,\n",
              " 59,\n",
              " 56,\n",
              " 57,\n",
              " 48,\n",
              " 34,\n",
              " 6,\n",
              " 38,\n",
              " 60,\n",
              " 25,\n",
              " 1,\n",
              " 16,\n",
              " 56,\n",
              " 6,\n",
              " 48,\n",
              " 33,\n",
              " 54,\n",
              " 33,\n",
              " 31,\n",
              " 20,\n",
              " 37,\n",
              " 0,\n",
              " 48,\n",
              " 2,\n",
              " 37,\n",
              " 17,\n",
              " 16,\n",
              " 0,\n",
              " 37,\n",
              " 59,\n",
              " 48,\n",
              " 47,\n",
              " 0,\n",
              " 37,\n",
              " 57,\n",
              " 56,\n",
              " 28,\n",
              " 37,\n",
              " 19,\n",
              " 57,\n",
              " 54,\n",
              " 33,\n",
              " 37,\n",
              " 57,\n",
              " 56,\n",
              " 37,\n",
              " 16,\n",
              " 25,\n",
              " 16,\n",
              " 0,\n",
              " 37,\n",
              " 48,\n",
              " 31,\n",
              " 37,\n",
              " 31,\n",
              " 33,\n",
              " 40,\n",
              " 2,\n",
              " 6,\n",
              " 33,\n",
              " 37,\n",
              " 57,\n",
              " 56,\n",
              " 37,\n",
              " 2,\n",
              " 34,\n",
              " 12,\n",
              " 33,\n",
              " 31,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 56,\n",
              " 33,\n",
              " 31,\n",
              " 17,\n",
              " 6,\n",
              " 38,\n",
              " 60,\n",
              " 48,\n",
              " 39,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 47,\n",
              " 31,\n",
              " 48,\n",
              " 18,\n",
              " 33,\n",
              " 59,\n",
              " 56,\n",
              " 37,\n",
              " 19,\n",
              " 2,\n",
              " 56,\n",
              " 33,\n",
              " 34,\n",
              " 14,\n",
              " 33,\n",
              " 31,\n",
              " 19,\n",
              " 37,\n",
              " 15,\n",
              " 57,\n",
              " 59,\n",
              " 33,\n",
              " 34,\n",
              " 6,\n",
              " 33,\n",
              " 37,\n",
              " 57,\n",
              " 34,\n",
              " 59,\n",
              " 15,\n",
              " 2,\n",
              " 12,\n",
              " 33,\n",
              " 12,\n",
              " 37,\n",
              " 25,\n",
              " 57,\n",
              " 56,\n",
              " 1,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 57,\n",
              " 6,\n",
              " 37,\n",
              " 33,\n",
              " 14,\n",
              " 48,\n",
              " 48,\n",
              " 26,\n",
              " 37,\n",
              " 48,\n",
              " 31,\n",
              " 37,\n",
              " 48,\n",
              " 34,\n",
              " 15,\n",
              " 57,\n",
              " 34,\n",
              " 33,\n",
              " 38,\n",
              " 60,\n",
              " 16,\n",
              " 56,\n",
              " 37,\n",
              " 25,\n",
              " 25,\n",
              " 25,\n",
              " 20,\n",
              " 19,\n",
              " 2,\n",
              " 56,\n",
              " 33,\n",
              " 34,\n",
              " 14,\n",
              " 33,\n",
              " 31,\n",
              " 19,\n",
              " 20,\n",
              " 48,\n",
              " 31,\n",
              " 19,\n",
              " 20,\n",
              " 37,\n",
              " 57,\n",
              " 39,\n",
              " 37,\n",
              " 0,\n",
              " 48,\n",
              " 2,\n",
              " 37,\n",
              " 16,\n",
              " 31,\n",
              " 33,\n",
              " 37,\n",
              " 34,\n",
              " 48,\n",
              " 56,\n",
              " 37,\n",
              " 15,\n",
              " 48,\n",
              " 59,\n",
              " 16,\n",
              " 56,\n",
              " 33,\n",
              " 12,\n",
              " 37,\n",
              " 57,\n",
              " 34,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 2,\n",
              " 34,\n",
              " 57,\n",
              " 56,\n",
              " 33,\n",
              " 12,\n",
              " 37,\n",
              " 6,\n",
              " 56,\n",
              " 16,\n",
              " 56,\n",
              " 33,\n",
              " 6,\n",
              " 28,\n",
              " 38,\n",
              " 60,\n",
              " 0,\n",
              " 48,\n",
              " 2,\n",
              " 37,\n",
              " 25,\n",
              " 57,\n",
              " 15,\n",
              " 15,\n",
              " 37,\n",
              " 1,\n",
              " 16,\n",
              " 54,\n",
              " 33,\n",
              " 37,\n",
              " 56,\n",
              " 48,\n",
              " 37,\n",
              " 59,\n",
              " 1,\n",
              " 33,\n",
              " 59,\n",
              " 26,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 15,\n",
              " 16,\n",
              " 25,\n",
              " 6,\n",
              " 37,\n",
              " 48,\n",
              " 39,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 59,\n",
              " 48,\n",
              " 2,\n",
              " 34,\n",
              " 56,\n",
              " 31,\n",
              " 0,\n",
              " 37,\n",
              " 25,\n",
              " 1,\n",
              " 33,\n",
              " 31,\n",
              " 33,\n",
              " 37,\n",
              " 0,\n",
              " 48,\n",
              " 2,\n",
              " 37,\n",
              " 16,\n",
              " 31,\n",
              " 33,\n",
              " 37,\n",
              " 15,\n",
              " 48,\n",
              " 59,\n",
              " 16,\n",
              " 56,\n",
              " 33,\n",
              " 12,\n",
              " 38,\n",
              " 60,\n",
              " 14,\n",
              " 33,\n",
              " 39,\n",
              " 48,\n",
              " 31,\n",
              " 33,\n",
              " 37,\n",
              " 2,\n",
              " 6,\n",
              " 57,\n",
              " 34,\n",
              " 19,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 57,\n",
              " 6,\n",
              " 37,\n",
              " 33,\n",
              " 14,\n",
              " 48,\n",
              " 48,\n",
              " 26,\n",
              " 20,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 56,\n",
              " 57,\n",
              " 56,\n",
              " 15,\n",
              " 33,\n",
              " 24,\n",
              " 37,\n",
              " 16,\n",
              " 15,\n",
              " 57,\n",
              " 59,\n",
              " 33,\n",
              " 62,\n",
              " 6,\n",
              " 37,\n",
              " 16,\n",
              " 12,\n",
              " 54,\n",
              " 33,\n",
              " 34,\n",
              " 56,\n",
              " 2,\n",
              " 31,\n",
              " 33,\n",
              " 6,\n",
              " 37,\n",
              " 57,\n",
              " 34,\n",
              " 37,\n",
              " 25,\n",
              " 48,\n",
              " 34,\n",
              " 12,\n",
              " 33,\n",
              " 31,\n",
              " 15,\n",
              " 16,\n",
              " 34,\n",
              " 12,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 16,\n",
              " 2,\n",
              " 56,\n",
              " 1,\n",
              " 48,\n",
              " 31,\n",
              " 24,\n",
              " 37,\n",
              " 15,\n",
              " 33,\n",
              " 25,\n",
              " 57,\n",
              " 6,\n",
              " 37,\n",
              " 59,\n",
              " 16,\n",
              " 31,\n",
              " 31,\n",
              " 48,\n",
              " 15,\n",
              " 15,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 31,\n",
              " 33,\n",
              " 15,\n",
              " 33,\n",
              " 16,\n",
              " 6,\n",
              " 33,\n",
              " 37,\n",
              " 12,\n",
              " 16,\n",
              " 56,\n",
              " 33,\n",
              " 24,\n",
              " 37,\n",
              " 18,\n",
              " 2,\n",
              " 34,\n",
              " 33,\n",
              " 37,\n",
              " 11,\n",
              " 44,\n",
              " 28,\n",
              " 37,\n",
              " 11,\n",
              " 49,\n",
              " 49,\n",
              " 5,\n",
              " 37,\n",
              " 3,\n",
              " 33,\n",
              " 14,\n",
              " 48,\n",
              " 48,\n",
              " 26,\n",
              " 37,\n",
              " 32,\n",
              " 53,\n",
              " 53,\n",
              " 9,\n",
              " 38,\n",
              " 60,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 17,\n",
              " 48,\n",
              " 6,\n",
              " 56,\n",
              " 37,\n",
              " 31,\n",
              " 33,\n",
              " 59,\n",
              " 33,\n",
              " 34,\n",
              " 56,\n",
              " 15,\n",
              " 0,\n",
              " 37,\n",
              " 2,\n",
              " 47,\n",
              " 12,\n",
              " 16,\n",
              " 56,\n",
              " 33,\n",
              " 12,\n",
              " 24,\n",
              " 37,\n",
              " 18,\n",
              " 2,\n",
              " 34,\n",
              " 33,\n",
              " 37,\n",
              " 11,\n",
              " 51,\n",
              " 28,\n",
              " 37,\n",
              " 11,\n",
              " 49,\n",
              " 11,\n",
              " 4,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 15,\n",
              " 16,\n",
              " 34,\n",
              " 19,\n",
              " 2,\n",
              " 16,\n",
              " 19,\n",
              " 33,\n",
              " 24,\n",
              " 37,\n",
              " 33,\n",
              " 34,\n",
              " 19,\n",
              " 15,\n",
              " 57,\n",
              " 6,\n",
              " 1,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 59,\n",
              " 31,\n",
              " 33,\n",
              " 12,\n",
              " 57,\n",
              " 56,\n",
              " 6,\n",
              " 24,\n",
              " 37,\n",
              " 16,\n",
              " 31,\n",
              " 56,\n",
              " 1,\n",
              " 2,\n",
              " 31,\n",
              " 37,\n",
              " 12,\n",
              " 57,\n",
              " 14,\n",
              " 57,\n",
              " 16,\n",
              " 34,\n",
              " 59,\n",
              " 16,\n",
              " 37,\n",
              " 16,\n",
              " 34,\n",
              " 12,\n",
              " 37,\n",
              " 12,\n",
              " 16,\n",
              " 54,\n",
              " 57,\n",
              " 12,\n",
              " 37,\n",
              " 25,\n",
              " 57,\n",
              " 12,\n",
              " 19,\n",
              " 33,\n",
              " 31,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 63,\n",
              " 63,\n",
              " 63,\n",
              " 37,\n",
              " 6,\n",
              " 56,\n",
              " 16,\n",
              " 31,\n",
              " 56,\n",
              " 37,\n",
              " 48,\n",
              " 39,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 47,\n",
              " 31,\n",
              " 48,\n",
              " 18,\n",
              " 33,\n",
              " 59,\n",
              " 56,\n",
              " 37,\n",
              " 19,\n",
              " 2,\n",
              " 56,\n",
              " 33,\n",
              " 34,\n",
              " 14,\n",
              " 33,\n",
              " 31,\n",
              " 19,\n",
              " 37,\n",
              " 33,\n",
              " 14,\n",
              " 48,\n",
              " 48,\n",
              " 26,\n",
              " 37,\n",
              " 16,\n",
              " 15,\n",
              " 57,\n",
              " 59,\n",
              " 33,\n",
              " 62,\n",
              " 6,\n",
              " 37,\n",
              " 16,\n",
              " 12,\n",
              " 54,\n",
              " 33,\n",
              " 34,\n",
              " 56,\n",
              " 2,\n",
              " 31,\n",
              " 33,\n",
              " 6,\n",
              " 37,\n",
              " 57,\n",
              " 34,\n",
              " 37,\n",
              " 25,\n",
              " 48,\n",
              " 34,\n",
              " 12,\n",
              " 33,\n",
              " 31,\n",
              " 15,\n",
              " 16,\n",
              " 34,\n",
              " 12,\n",
              " 37,\n",
              " 63,\n",
              " 63,\n",
              " 63,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 3,\n",
              " 57,\n",
              " 15,\n",
              " 15,\n",
              " 2,\n",
              " 6,\n",
              " 56,\n",
              " 31,\n",
              " 16,\n",
              " 56,\n",
              " 57,\n",
              " 48,\n",
              " 34,\n",
              " 9,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 16,\n",
              " 15,\n",
              " 57,\n",
              " 59,\n",
              " 33,\n",
              " 22,\n",
              " 6,\n",
              " 37,\n",
              " 16,\n",
              " 12,\n",
              " 54,\n",
              " 33,\n",
              " 34,\n",
              " 56,\n",
              " 2,\n",
              " 31,\n",
              " 33,\n",
              " 6,\n",
              " 37,\n",
              " 57,\n",
              " 34,\n",
              " 37,\n",
              " 25,\n",
              " 48,\n",
              " 34,\n",
              " 12,\n",
              " 33,\n",
              " 31,\n",
              " 15,\n",
              " 16,\n",
              " 34,\n",
              " 12,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 14,\n",
              " 0,\n",
              " 37,\n",
              " 15,\n",
              " 33,\n",
              " 25,\n",
              " 57,\n",
              " 6,\n",
              " 37,\n",
              " 59,\n",
              " 16,\n",
              " 31,\n",
              " 31,\n",
              " 48,\n",
              " 15,\n",
              " 15,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 17,\n",
              " 57,\n",
              " 15,\n",
              " 15,\n",
              " 33,\n",
              " 34,\n",
              " 34,\n",
              " 57,\n",
              " 2,\n",
              " 17,\n",
              " 37,\n",
              " 39,\n",
              " 2,\n",
              " 15,\n",
              " 59,\n",
              " 31,\n",
              " 2,\n",
              " 17,\n",
              " 37,\n",
              " 33,\n",
              " 12,\n",
              " 57,\n",
              " 56,\n",
              " 57,\n",
              " 48,\n",
              " 34,\n",
              " 37,\n",
              " 52,\n",
              " 20,\n",
              " 49,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 59,\n",
              " 48,\n",
              " 34,\n",
              " 56,\n",
              " 33,\n",
              " 34,\n",
              " 56,\n",
              " 6,\n",
              " 38,\n",
              " 60,\n",
              " 38,\n",
              " 60,\n",
              " 37,\n",
              " 59,\n",
              " 1,\n",
              " 16,\n",
              " 47,\n",
              " 56,\n",
              " 33,\n",
              " 31,\n",
              " 37,\n",
              " 57,\n",
              " 20,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 37,\n",
              " 12,\n",
              " 48,\n",
              " 25,\n",
              " 34,\n",
              " 37,\n",
              " 56,\n",
              " 1,\n",
              " 33,\n",
              " 37,\n",
              " 31,\n",
              " 16,\n",
              " 14,\n",
              " 14,\n",
              " 57,\n",
              " 56,\n",
              " 40,\n",
              " 1]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tokenized_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### 0.3 Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "train_text = tokenized_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KFAyA4zCWE-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08dd6e4-781f-4050-c9fc-0a0a6158f6a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150774, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qcKRl70HFTzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b83e64-8123-4091-e49d-5e3930509df8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([56,  1, 33, 37, 47, 31, 48, 18, 33, 59])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "X[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TVpLCKSZFXZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b56eb96b-921f-4197-ea45-b694d213ecf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1, 33, 37, 47, 31, 48, 18, 33, 59, 56])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "y[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wOFCR-KqbW1N"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(chars_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "## 1. Definiendo Los Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Definiremos 3 modelos en PyTorch para comparar su performance: celda de Elman (RNN basica), LSTM y GRU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "class PerplexityEvaluator:\n",
        "    \"\"\"\n",
        "    Evalúa la perplejidad promedio sobre el conjunto de validación.\n",
        "    Usa CrossEntropyLoss directamente (coherente con el entrenamiento).\n",
        "    Incluye early stopping y guardado del mejor modelo.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X_val, y_val, model, device,\n",
        "                 patience=5, save_path=\"best_model.pt\", eval_batch_size=64):\n",
        "        \"\"\"\n",
        "        X_val, y_val: tensores o arrays numpy del conjunto de validación\n",
        "        model: instancia del modelo PyTorch\n",
        "        device: torch.device(\"cuda\" o \"cpu\")\n",
        "        patience: epochs sin mejora antes de early stopping\n",
        "        save_path: ruta para guardar el mejor modelo\n",
        "        eval_batch_size: tamaño de batch en validación\n",
        "        \"\"\"\n",
        "        # convertir arrays numpy a tensores si es necesario\n",
        "        if isinstance(X_val, np.ndarray):\n",
        "            X_val = torch.tensor(X_val, dtype=torch.long)\n",
        "        if isinstance(y_val, np.ndarray):\n",
        "            y_val = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "        self.inputs = X_val\n",
        "        self.targets = y_val\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.patience = patience\n",
        "        self.save_path = save_path\n",
        "        self.eval_batch_size = eval_batch_size\n",
        "\n",
        "        self.min_score = np.inf\n",
        "        self.patience_counter = 0\n",
        "        self.history_ppl = []\n",
        "\n",
        "    def compute_perplexity(self):\n",
        "        \"\"\"Evalúa la perplejidad promedio en batches.\"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        total_tokens = 0\n",
        "        criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "\n",
        "        dataset = TensorDataset(self.inputs, self.targets)\n",
        "        loader = DataLoader(dataset, batch_size=self.eval_batch_size, shuffle=False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in loader:\n",
        "                X_batch = X_batch.to(self.device)\n",
        "                y_batch = y_batch.to(self.device)\n",
        "\n",
        "                try:\n",
        "                    outputs, _ = self.model(X_batch)\n",
        "                except RuntimeError as e:\n",
        "                    if \"out of memory\" in str(e).lower():\n",
        "                        print(\"⚠️ GPU sin memoria — evaluando perplejidad en CPU temporalmente.\")\n",
        "                        torch.cuda.empty_cache()\n",
        "                        self.model.to(\"cpu\")\n",
        "                        X_batch = X_batch.to(\"cpu\")\n",
        "                        y_batch = y_batch.to(\"cpu\")\n",
        "                        outputs, _ = self.model(X_batch)\n",
        "                        self.model.to(self.device)\n",
        "                    else:\n",
        "                        raise e\n",
        "\n",
        "                loss = criterion(outputs.view(-1, self.model.fc.out_features),\n",
        "                                 y_batch.view(-1))\n",
        "                total_loss += loss.item()\n",
        "                total_tokens += y_batch.numel()\n",
        "\n",
        "        mean_loss = total_loss / total_tokens\n",
        "        ppl = np.exp(mean_loss)\n",
        "        return ppl\n",
        "\n",
        "    def on_epoch_end(self, epoch):\n",
        "        \"\"\"Calcula perplejidad, guarda modelo si mejora y aplica early stopping.\"\"\"\n",
        "        ppl = self.compute_perplexity()\n",
        "        self.history_ppl.append(ppl)\n",
        "        print(f\"Epoch {epoch+1} — Mean Perplexity: {ppl:.3f}\")\n",
        "\n",
        "        if ppl < self.min_score:\n",
        "            self.min_score = ppl\n",
        "            self.patience_counter = 0\n",
        "            torch.save(self.model.state_dict(), self.save_path)\n",
        "            print(\"✅ Saved new best model.\")\n",
        "        else:\n",
        "            self.patience_counter += 1\n",
        "            if self.patience_counter >= self.patience:\n",
        "                print(\"⛔ Early stopping triggered.\")\n",
        "                return True\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "f4z6E40QCmip"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 SimpleRNN"
      ],
      "metadata": {
        "id": "8JDIm4lYCOWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleRNNLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size=200, emb_dim=128, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # embedding para reemplazar one-hot\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=emb_dim)\n",
        "\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=emb_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        # x: [batch, seq_len]\n",
        "        x_emb = self.embedding(x)             # [batch, seq_len, emb_dim]\n",
        "        out, hidden = self.rnn(x_emb, hidden) # [batch, seq_len, hidden_size]\n",
        "        logits = self.fc(out)                 # [batch, seq_len, vocab_size]\n",
        "        return logits, hidden\n"
      ],
      "metadata": {
        "id": "0hRZSw3OCTFn"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 LSTM"
      ],
      "metadata": {
        "id": "wz95TINWCQjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "class LSTMLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size=200, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.LSTM(vocab_size, hidden_size, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = F.one_hot(x, num_classes=self.fc.out_features).float()\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        return self.fc(out), hidden\n"
      ],
      "metadata": {
        "id": "-BUTSIXdCStJ"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 GRU"
      ],
      "metadata": {
        "id": "dghUOgrXCTjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRULanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size=200, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.GRU(vocab_size, hidden_size, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = F.one_hot(x, num_classes=self.fc.out_features).float()\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        return self.fc(out), hidden"
      ],
      "metadata": {
        "id": "2e_H5UyEC6R7"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "## 2. Entrenamiento de los modelos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_data, device, vocab_size,\n",
        "                max_context_size,\n",
        "                n_epochs=20, lr=0.001, patience=5, model_name=\"model\"\n",
        "                ):\n",
        "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    evaluator = PerplexityEvaluator(\n",
        "        X_val, y_val,\n",
        "        model=model,\n",
        "        device=device,\n",
        "        patience=5,\n",
        "        save_path=f\"{model_name}_best.pt\",\n",
        "        eval_batch_size=32\n",
        "    )\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs, _ = model(X_batch)\n",
        "            loss = criterion(outputs.view(-1, vocab_size), y_batch.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"\\nEpoch {epoch+1}/{n_epochs} — Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Calcular perplejidad y chequear early stopping\n",
        "        stop = evaluator.on_epoch_end(epoch)\n",
        "        if stop:\n",
        "            print(f\"Entrenamiento detenido en epoch {epoch+1} (early stopping).\")\n",
        "            break\n",
        "\n",
        "    # 🔹 Guardar el modelo final (último epoch entrenado)\n",
        "    final_path = f\"{model_name}_final.pt\"\n",
        "    torch.save(model.state_dict(), final_path)\n",
        "    print(f\"Modelo final guardado en: {final_path}\")\n",
        "    print(f\"Mejor modelo guardado en: {model_name}_best.pt\")\n",
        "\n",
        "    return evaluator.history_ppl, model\n"
      ],
      "metadata": {
        "id": "1DfV9e_uDBNZ"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"- Vocab size: \", vocab_size)\n",
        "print(\"- Context Len:\", max_context_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5QxwXk3DKf6",
        "outputId": "81efe048-3a44-4c0d-de57-fcc7acffa30c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Vocab size:  65\n",
            "- Context Len: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "LR = 0.001\n",
        "PATIENCE = 5\n",
        "\n",
        "seq_len = max_context_size\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
        "X_val_t   = torch.tensor(X_val, dtype=torch.long)\n",
        "y_val_t   = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "val_dataset   = TensorDataset(X_val_t, y_val_t)\n",
        "\n",
        "# 4️⃣ DataLoaders (listas para tu loop)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "# Datos de validación (listas de secuencias)\n",
        "val_data = [seq.tolist() for seq in X_val_t]  # compatible con tu callback\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Entrenar los tres modelos\n",
        "models = {\n",
        "    \"SimpleRNN\": SimpleRNNLanguageModel(vocab_size),\n",
        "    \"LSTM\": LSTMLanguageModel(vocab_size),\n",
        "    \"GRU\": GRULanguageModel(vocab_size)\n",
        "}\n",
        "\n",
        "history = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n- Entrenando {name}...\")\n",
        "    model.to(device)\n",
        "    history[name], model = train_model(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_data=val_data,\n",
        "        device=device,\n",
        "        vocab_size=vocab_size,\n",
        "        n_epochs=EPOCHS,\n",
        "        max_context_size=seq_len,\n",
        "        lr=LR,\n",
        "        patience=PATIENCE,\n",
        "        model_name=name,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpcgQ54GDDtD",
        "outputId": "22614aaa-0e92-4c24-c703-84050b867026"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- Entrenando SimpleRNN...\n",
            "\n",
            "Epoch 1/20 — Loss: 1.2941\n",
            "Epoch 1 — Mean Perplexity: 3.013\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 2/20 — Loss: 1.0425\n",
            "Epoch 2 — Mean Perplexity: 2.737\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 3/20 — Loss: 0.9867\n",
            "Epoch 3 — Mean Perplexity: 2.660\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 4/20 — Loss: 0.9677\n",
            "Epoch 4 — Mean Perplexity: 2.614\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 5/20 — Loss: 0.9577\n",
            "Epoch 5 — Mean Perplexity: 2.614\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 6/20 — Loss: 0.9522\n",
            "Epoch 6 — Mean Perplexity: 2.607\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 7/20 — Loss: 0.9479\n",
            "Epoch 7 — Mean Perplexity: 2.595\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 8/20 — Loss: 0.9445\n",
            "Epoch 8 — Mean Perplexity: 2.596\n",
            "\n",
            "Epoch 9/20 — Loss: 0.9415\n",
            "Epoch 9 — Mean Perplexity: 2.573\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 10/20 — Loss: 0.9390\n",
            "Epoch 10 — Mean Perplexity: 2.572\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 11/20 — Loss: 0.9363\n",
            "Epoch 11 — Mean Perplexity: 2.564\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 12/20 — Loss: 0.9348\n",
            "Epoch 12 — Mean Perplexity: 2.547\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 13/20 — Loss: 0.9325\n",
            "Epoch 13 — Mean Perplexity: 2.553\n",
            "\n",
            "Epoch 14/20 — Loss: 0.9309\n",
            "Epoch 14 — Mean Perplexity: 2.579\n",
            "\n",
            "Epoch 15/20 — Loss: 0.9291\n",
            "Epoch 15 — Mean Perplexity: 2.544\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 16/20 — Loss: 0.9275\n",
            "Epoch 16 — Mean Perplexity: 2.549\n",
            "\n",
            "Epoch 17/20 — Loss: 0.9262\n",
            "Epoch 17 — Mean Perplexity: 2.536\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 18/20 — Loss: 0.9247\n",
            "Epoch 18 — Mean Perplexity: 2.523\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 19/20 — Loss: 0.9233\n",
            "Epoch 19 — Mean Perplexity: 2.537\n",
            "\n",
            "Epoch 20/20 — Loss: 0.9220\n",
            "Epoch 20 — Mean Perplexity: 2.525\n",
            "Modelo final guardado en: SimpleRNN_final.pt\n",
            "Mejor modelo guardado en: SimpleRNN_best.pt\n",
            "\n",
            "- Entrenando LSTM...\n",
            "\n",
            "Epoch 1/20 — Loss: 1.4316\n",
            "Epoch 1 — Mean Perplexity: 2.707\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 2/20 — Loss: 0.8300\n",
            "Epoch 2 — Mean Perplexity: 2.038\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 3/20 — Loss: 0.6499\n",
            "Epoch 3 — Mean Perplexity: 1.824\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 4/20 — Loss: 0.5607\n",
            "Epoch 4 — Mean Perplexity: 1.717\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 5/20 — Loss: 0.5067\n",
            "Epoch 5 — Mean Perplexity: 1.637\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 6/20 — Loss: 0.4698\n",
            "Epoch 6 — Mean Perplexity: 1.611\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 7/20 — Loss: 0.4424\n",
            "Epoch 7 — Mean Perplexity: 1.571\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 8/20 — Loss: 0.4213\n",
            "Epoch 8 — Mean Perplexity: 1.512\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 9/20 — Loss: 0.4043\n",
            "Epoch 9 — Mean Perplexity: 1.491\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 10/20 — Loss: 0.3904\n",
            "Epoch 10 — Mean Perplexity: 1.478\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 11/20 — Loss: 0.3787\n",
            "Epoch 11 — Mean Perplexity: 1.464\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 12/20 — Loss: 0.3691\n",
            "Epoch 12 — Mean Perplexity: 1.443\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 13/20 — Loss: 0.3607\n",
            "Epoch 13 — Mean Perplexity: 1.435\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 14/20 — Loss: 0.3532\n",
            "Epoch 14 — Mean Perplexity: 1.427\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 15/20 — Loss: 0.3467\n",
            "Epoch 15 — Mean Perplexity: 1.426\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 16/20 — Loss: 0.3406\n",
            "Epoch 16 — Mean Perplexity: 1.434\n",
            "\n",
            "Epoch 17/20 — Loss: 0.3353\n",
            "Epoch 17 — Mean Perplexity: 1.403\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 18/20 — Loss: 0.3304\n",
            "Epoch 18 — Mean Perplexity: 1.390\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 19/20 — Loss: 0.3262\n",
            "Epoch 19 — Mean Perplexity: 1.400\n",
            "\n",
            "Epoch 20/20 — Loss: 0.3222\n",
            "Epoch 20 — Mean Perplexity: 1.390\n",
            "Modelo final guardado en: LSTM_final.pt\n",
            "Mejor modelo guardado en: LSTM_best.pt\n",
            "\n",
            "- Entrenando GRU...\n",
            "\n",
            "Epoch 1/20 — Loss: 1.3400\n",
            "Epoch 1 — Mean Perplexity: 2.577\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 2/20 — Loss: 0.8101\n",
            "Epoch 2 — Mean Perplexity: 2.072\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 3/20 — Loss: 0.6823\n",
            "Epoch 3 — Mean Perplexity: 1.915\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 4/20 — Loss: 0.6230\n",
            "Epoch 4 — Mean Perplexity: 1.845\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 5/20 — Loss: 0.5860\n",
            "Epoch 5 — Mean Perplexity: 1.786\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 6/20 — Loss: 0.5596\n",
            "Epoch 6 — Mean Perplexity: 1.759\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 7/20 — Loss: 0.5397\n",
            "Epoch 7 — Mean Perplexity: 1.725\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 8/20 — Loss: 0.5238\n",
            "Epoch 8 — Mean Perplexity: 1.682\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 9/20 — Loss: 0.5107\n",
            "Epoch 9 — Mean Perplexity: 1.678\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 10/20 — Loss: 0.4997\n",
            "Epoch 10 — Mean Perplexity: 1.653\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 11/20 — Loss: 0.4903\n",
            "Epoch 11 — Mean Perplexity: 1.632\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 12/20 — Loss: 0.4822\n",
            "Epoch 12 — Mean Perplexity: 1.660\n",
            "\n",
            "Epoch 13/20 — Loss: 0.4752\n",
            "Epoch 13 — Mean Perplexity: 1.609\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 14/20 — Loss: 0.4688\n",
            "Epoch 14 — Mean Perplexity: 1.609\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 15/20 — Loss: 0.4635\n",
            "Epoch 15 — Mean Perplexity: 1.609\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 16/20 — Loss: 0.4585\n",
            "Epoch 16 — Mean Perplexity: 1.586\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 17/20 — Loss: 0.4538\n",
            "Epoch 17 — Mean Perplexity: 1.577\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 18/20 — Loss: 0.4497\n",
            "Epoch 18 — Mean Perplexity: 1.580\n",
            "\n",
            "Epoch 19/20 — Loss: 0.4455\n",
            "Epoch 19 — Mean Perplexity: 1.569\n",
            "✅ Saved new best model.\n",
            "\n",
            "Epoch 20/20 — Loss: 0.4423\n",
            "Epoch 20 — Mean Perplexity: 1.554\n",
            "✅ Saved new best model.\n",
            "Modelo final guardado en: GRU_final.pt\n",
            "Mejor modelo guardado en: GRU_best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for name, h in history.items():\n",
        "    plt.plot(h, label=name)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Perplexity\")\n",
        "plt.legend()\n",
        "plt.title(\"Evolución de la perplejidad por modelo\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "vz8j4gILF5hg",
        "outputId": "802d9e50-30cc-4c94-8f57-1d4b6ad50863"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "## 3. Predicción del próximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "IBvKHFPmzpy2"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_type):\n",
        "    \"\"\"\n",
        "    Carga el modelo seleccionado desde su archivo *_best.pt.\n",
        "    \"\"\"\n",
        "    model_map = {\n",
        "        \"SimpleRNN\": SimpleRNNLanguageModel,\n",
        "        \"LSTM\": LSTMLanguageModel,\n",
        "        \"GRU\": GRULanguageModel\n",
        "    }\n",
        "    model_class = model_map[model_type]\n",
        "    model = model_class(vocab_size=len(char2idx))\n",
        "    model_path = f\"{model_type}_best.pt\"\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        print(f\"✅ Modelo {model_type} cargado desde {model_path}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"⚠️ No se encontró el archivo {model_path}. Asegurate de haberlo entrenado.\")\n",
        "        model = None\n",
        "    return model"
      ],
      "metadata": {
        "id": "v8zGkLrfTM6L"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequence_np(seq, maxlen, pad_value=0):\n",
        "    seq = np.array(seq)\n",
        "    if len(seq) < maxlen:\n",
        "        pad = np.full(maxlen - len(seq), pad_value)\n",
        "        return np.concatenate([pad, seq])\n",
        "    else:\n",
        "        return seq[-maxlen:]\n",
        "\n",
        "def model_response(human_text, model_type):\n",
        "    if len(human_text.strip()) == 0:\n",
        "        return \"\"\n",
        "\n",
        "    model = load_model(model_type)\n",
        "    if model is None:\n",
        "        return f\"❌ No se encontró el modelo {model_type}_best.pt\"\n",
        "\n",
        "    # 1️⃣ Codificar el texto\n",
        "    encoded = [char2idx.get(ch.lower(), 0) for ch in human_text]\n",
        "    encoded = pad_sequence_np(encoded, max_context_size)\n",
        "    encoded = torch.tensor(encoded, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    # 2️⃣ Inferencia\n",
        "    with torch.no_grad():\n",
        "        outputs, _ = model(encoded)\n",
        "        logits = outputs[:, -1, :]\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        y_hat = torch.argmax(probs, dim=-1).item()\n",
        "\n",
        "    # 3️⃣ Decodificar y devolver\n",
        "    next_char = idx2char[y_hat]\n",
        "    return human_text + next_char"
      ],
      "metadata": {
        "id": "axLUbBm2TQo_"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Ingresa texto\"),\n",
        "        gr.Radio([\"SimpleRNN\", \"LSTM\", \"GRU\"], label=\"Seleccionar modelo\", value=\"SimpleRNN\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Predicción del modelo\"),\n",
        "    title=\"🧠 Generador de texto RNN/LSTM/GRU (PyTorch)\",\n",
        "    description=\"Seleccioná el modelo y generá el siguiente carácter predicho.\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "id": "PzxCqZxATTus",
        "outputId": "c4f8dda8-2661-42e3-8375-bf03b2ffd98f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://34bfe93644808d25be.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://34bfe93644808d25be.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo SimpleRNN cargado desde SimpleRNN_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo SimpleRNN cargado desde SimpleRNN_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo LSTM cargado desde LSTM_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo GRU cargado desde GRU_best.pt\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://34bfe93644808d25be.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### 3.1 Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "    Genera texto autoregresivamente con un modelo PyTorch.\n",
        "    Args:\n",
        "        model (torch.nn.Module): modelo entrenado (SimpleRNN, LSTM o GRU)\n",
        "        seed_text (str): texto de entrada (contexto inicial)\n",
        "        max_length (int): longitud máxima de la secuencia de entrada (contexto)\n",
        "        n_words (int): cantidad de caracteres a generar\n",
        "    Returns:\n",
        "        str: texto generado (semilla + predicciones)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    output_text = seed_text\n",
        "\n",
        "    for _ in range(n_words):\n",
        "        # 1️⃣ Encodear texto actual\n",
        "        encoded = [char2idx.get(ch.lower(), 0) for ch in output_text]\n",
        "        if len(encoded) < max_length:\n",
        "            pad = [0] * (max_length - len(encoded))\n",
        "            encoded = pad + encoded\n",
        "        else:\n",
        "            encoded = encoded[-max_length:]\n",
        "\n",
        "        # Convertir a tensor\n",
        "        x = torch.tensor(encoded, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "        # 2️⃣ Forward pass\n",
        "        with torch.no_grad():\n",
        "            outputs, _ = model(x)\n",
        "            logits = outputs[:, -1, :]  # solo el último paso temporal\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            y_hat = torch.argmax(probs, dim=-1).item()\n",
        "\n",
        "        # 3️⃣ Decodificar y agregar carácter\n",
        "        out_char = idx2char[y_hat]\n",
        "        output_text += out_char\n",
        "\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "JoFqRC5pxzqS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e104149-4806-4f4c-9233-5d799ec88890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://3a0951aa0e6dfc9649.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3a0951aa0e6dfc9649.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo SimpleRNN cargado desde SimpleRNN_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo LSTM cargado desde LSTM_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo GRU cargado desde GRU_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo GRU cargado desde GRU_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo LSTM cargado desde LSTM_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo SimpleRNN cargado desde SimpleRNN_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo SimpleRNN cargado desde SimpleRNN_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo LSTM cargado desde LSTM_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo GRU cargado desde GRU_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo GRU cargado desde GRU_best.pt\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://3a0951aa0e6dfc9649.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "def model_response(seed_text, model_type, n_chars):\n",
        "    model = load_model(model_type)\n",
        "    generated = generate_seq(model, seed_text, max_context_size, int(n_chars))\n",
        "    return generated\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Texto inicial (semilla)\", placeholder=\"Escribí un inicio...\"),\n",
        "        gr.Radio([\"SimpleRNN\", \"LSTM\", \"GRU\"], label=\"Seleccionar modelo\", value=\"SimpleRNN\"),\n",
        "        gr.Slider(1, 200, value=50, step=1, label=\"Cantidad de caracteres a generar\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Texto generado\"),\n",
        "    title=\"🧠 Generador de texto con RNN / LSTM / GRU (PyTorch)\",\n",
        "    description=\"Seleccioná un modelo y generá texto autoregresivamente.\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Análisis:** Notamos que en todos los casos (los 3 modelos) se refleja informacion aprendida del libro utilizado como dataset (alice in wonderland), pero no se generan oraciones ni palabras coherentes!"
      ],
      "metadata": {
        "id": "x0ZbzJ0aXt5i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  3.2 Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# ENCODE / DECODE\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def encode(text, max_length=max_context_size):\n",
        "    \"\"\"Codifica texto en tensores PyTorch con padding previo.\"\"\"\n",
        "    encoded = [char2idx.get(ch, 0) for ch in text.lower()]\n",
        "    if len(encoded) < max_length:\n",
        "        pad = [0] * (max_length - len(encoded))\n",
        "        encoded = pad + encoded\n",
        "    else:\n",
        "        encoded = encoded[-max_length:]\n",
        "    x = torch.tensor(encoded, dtype=torch.long).unsqueeze(0).to(device)\n",
        "    return x\n",
        "\n",
        "def decode(seq):\n",
        "    \"\"\"Convierte una secuencia de índices en texto.\"\"\"\n",
        "    return ''.join([idx2char[i] for i in seq])\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# SELECT CANDIDATES\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def select_candidates(preds, num_beams, vocab_size, history_probs, history_tokens, temp, mode):\n",
        "    \"\"\"\n",
        "    Selecciona los mejores candidatos del beam actual.\n",
        "    preds: lista de arrays (num_beams × vocab_size)\n",
        "    \"\"\"\n",
        "    pred_large = []\n",
        "\n",
        "    for idx, pp in enumerate(preds):\n",
        "        pred_large.extend(np.log(pp + 1e-10) + history_probs[idx])\n",
        "\n",
        "    pred_large = np.array(pred_large)\n",
        "\n",
        "    # Criterio de selección\n",
        "    if mode == 'det':\n",
        "        idx_select = np.argsort(pred_large)[::-1][:num_beams]\n",
        "    elif mode == 'sto':\n",
        "        idx_select = np.random.choice(\n",
        "            np.arange(pred_large.shape[0]),\n",
        "            num_beams,\n",
        "            p=softmax(pred_large / temp)\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Wrong selection mode '{mode}'. Use 'det' or 'sto'.\")\n",
        "\n",
        "    # Indices reales\n",
        "    new_history_tokens = np.concatenate(\n",
        "        (np.array(history_tokens)[idx_select // vocab_size],\n",
        "         np.array([idx_select % vocab_size]).T),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# BEAM SEARCH (PyTorch version)\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def beam_search(model, num_beams, num_words, input_text, temp=1, mode='det'):\n",
        "    \"\"\"\n",
        "    Implementación de beam search usando un modelo PyTorch.\n",
        "    Devuelve TODAS las secuencias generadas + la mejor.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # 1️⃣ Primera iteración\n",
        "    encoded = encode(input_text)\n",
        "    with torch.no_grad():\n",
        "        outputs, _ = model(encoded)\n",
        "        y_hat = torch.softmax(outputs[:, -1, :], dim=-1).cpu().numpy()[0]\n",
        "\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # Inicialización\n",
        "    history_probs = np.zeros(num_beams)\n",
        "    history_tokens = [encoded.cpu().numpy()[0]] * num_beams\n",
        "\n",
        "    # Selección inicial\n",
        "    history_probs, history_tokens = select_candidates(\n",
        "        [y_hat], num_beams, vocab_size,\n",
        "        history_probs, history_tokens, temp, mode\n",
        "    )\n",
        "\n",
        "    # 2️⃣ Loop de búsqueda\n",
        "    for _ in range(num_words - 1):\n",
        "        preds = []\n",
        "        for hist in history_tokens:\n",
        "            input_update = torch.tensor([hist[-max_context_size:]], dtype=torch.long).to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs, _ = model(input_update)\n",
        "                y_hat = torch.softmax(outputs[:, -1, :], dim=-1).cpu().numpy()[0]\n",
        "            preds.append(y_hat)\n",
        "\n",
        "        history_probs, history_tokens = select_candidates(\n",
        "            preds, num_beams, vocab_size,\n",
        "            history_probs, history_tokens, temp, mode\n",
        "        )\n",
        "\n",
        "    # 3️⃣ Ranking final\n",
        "    ranked_indices = np.argsort(history_probs)[::-1]\n",
        "    ranked_probs = history_probs[ranked_indices]\n",
        "    ranked_tokens = history_tokens[ranked_indices]\n",
        "\n",
        "    # 4️⃣ Decodificación\n",
        "    decoded_sequences = [\n",
        "        decode(seq[-(len(input_text) + num_words):]) for seq in ranked_tokens\n",
        "    ]\n",
        "\n",
        "    # 5️⃣ Empaquetado de resultados\n",
        "    results = [\n",
        "        {\"rank\": i + 1,\n",
        "         \"log_prob\": float(ranked_probs[i]),\n",
        "         \"text\": decoded_sequences[i]}\n",
        "        for i in range(len(decoded_sequences))\n",
        "    ]\n",
        "\n",
        "    best_seq = decoded_sequences[0]\n",
        "    return best_seq, results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "GeLqAoOYW1Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b80559-39ce-468d-8459-610557f16088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏆 Mejor beam:\n",
            "alice curiosion of the project gutenberg™ trademark. con\n",
            "\n",
            "🔍 Otros candidatos:\n",
            "[1] logP=-7.69 → alice curiosion of the project gutenberg™ trademark. con\n",
            "[2] logP=-8.35 → alice curiosion of the project gutenberg™ trademark, and\n",
            "[3] logP=-8.96 → alice curiosion of the project\r\n",
            "gutenberg™ trademark, an\n",
            "[4] logP=-9.33 → alice curiosion of the project\r\n",
            "gutenberg™ trademark. co\n",
            "[5] logP=-10.85 → alice curiosion of the project gutenberg™ trademark. cun\n"
          ]
        }
      ],
      "source": [
        "# Texto semilla\n",
        "seed = \"Alice \"\n",
        "\n",
        "# Beam search determinista\n",
        "best, beams = beam_search(model, num_beams=5, num_words=50, input_text=seed, mode=\"det\")\n",
        "\n",
        "print(\"🏆 Mejor beam:\")\n",
        "print(best)\n",
        "\n",
        "print(\"\\n🔍 Otros candidatos:\")\n",
        "for b in beams:\n",
        "    print(f\"[{b['rank']}] logP={b['log_prob']:.2f} → {b['text']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto semilla\n",
        "seed = \"Alice\"\n",
        "\n",
        "# Beam search determinista\n",
        "best, beams = beam_search(model, num_beams=5, num_words=50, input_text=seed, mode=\"sto\")\n",
        "\n",
        "print(\"🏆 Mejor beam:\")\n",
        "print(best)\n",
        "\n",
        "print(\"\\n🔍 Otros candidatos:\")\n",
        "for b in beams:\n",
        "    print(f\"[{b['rank']}] logP={b['log_prob']:.2f} → {b['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9jIx5ouYFq8",
        "outputId": "3a2cc6a8-0f7d-4946-d3c3-1d673172b160"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏆 Mejor beam:\n",
            "aliced,” said the king.\r\n",
            "\r\n",
            "here one of the project gute\n",
            "\n",
            "🔍 Otros candidatos:\n",
            "[1] logP=-8.42 → aliced,” said the king.\r\n",
            "\r\n",
            "here one of the project gute\n",
            "[2] logP=-8.42 → aliced,” said the king.\r\n",
            "\r\n",
            "here one of the project gute\n",
            "[3] logP=-8.42 → aliced,” said the king.\r\n",
            "\r\n",
            "here one of the project gute\n",
            "[4] logP=-8.42 → aliced,” said the king.\r\n",
            "\r\n",
            "here one of the project gute\n",
            "[5] logP=-8.42 → aliced,” said the king.\r\n",
            "\r\n",
            "here one of the project gute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1UNHQEeYGE5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "desafios nlp 1",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}