<p align="center">
  <img src="./logoFIUBA.jpg" alt="FIUBA Logo" width="600"/>
</p>

# üìò Diplomatura en Procesamiento del Lenguaje Natural ‚Äî NLP 1

Este repositorio contiene el material y los trabajos pr√°cticos desarrollados durante la materia **NLP 1** de la **Diplomatura en Procesamiento del Lenguaje Natural (FIUBA)**.  
La asignatura introduce los fundamentos del procesamiento de texto con Python, modelos estad√≠sticos y redes neuronales recurrentes aplicadas al modelado del lenguaje.

---

üìé [Mi perfil de LinkedIn](https://www.linkedin.com/in/lucasargento)

---

## üß† Sobre la materia

La materia **NLP 1** cubre los principios b√°sicos del procesamiento de lenguaje natural (PLN), incluyendo:
- Preprocesamiento y tokenizaci√≥n de texto.  
- Representaciones distribuidas (embeddings, one-hot, etc.).  
- Modelado de lenguaje con **redes neuronales recurrentes (RNN, LSTM, GRU)** e intro a **transformers y attention**.  
- Estrategias de generaci√≥n de texto como *greedy search* y *beam search*.  
- Evaluaci√≥n mediante m√©tricas como **perplejidad**.

---

## üìÇ Estructura del repositorio

Dentro del repositorio vas a encontrar dos carpetas principales:

- **clases/clase_N/**: En esta carpeta se agrupa el material te√≥rico-pr√°ctico, organizado por clase. Cada subcarpeta `clase_N` corresponde a la clase N de la materia e incluye notebooks, ejemplos, y recursos utilizados en cada cursada.

- **tps_desafios/**: Aqu√≠ se encuentran las entregas de los trabajos pr√°cticos y desaf√≠os realizados a lo largo del curso. Cada TP o desaf√≠o est√° subdividido en carpetas propias con las resoluciones correspondientes.

### üìö Trabajos pr√°cticos (TPs)

> - **TP1 ‚Äî Vectorizaci√≥n con TFIDF, modelos por prototipos de vectores y similaridad coseno, clasificaci√≥n con Naive Bayes + TFIDF**  
> - **TP2 ‚Äî Creacion de custom embeddings con Gensim. Embeddings entrenados con canciones de Bob Marley.**  
> - **TP3 ‚Äî Generaci√≥n de texto caracter-a-caracter con arquitecturas recurrentes: SimpleRNN (Elman), LSTM y GRU. Entrenadas sobre un libro de Alicia en el Pa√≠s de las Maravillas. Implementacion de beam search sobre secuencias generadas por los modelos**  
> - **TP4 ‚Äî Generaci√≥n de texto seq-to-seq. Creaci√≥n de un bot de QA con arquitectura encoder-decoder y LSTMs. Aplicacion de beam search sobre inferencia autoregresiva. Embeddings entrenables de Glove en encoder/decoder.**

