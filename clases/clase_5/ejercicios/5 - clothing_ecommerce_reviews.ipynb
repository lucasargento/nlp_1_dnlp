{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"kBLpTr7plguX"},"source":["<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Sentiment analysis con Embeddings + LSTM"]},{"cell_type":"markdown","metadata":{"id":"9W6nuajhlqZD"},"source":["### Objetivo\n","El objetivo es utilizar las críticas de compradores de ropa para que el sistema determine la evaluación del comprador y su crítica (cuantas estrellas le asigna al producto)."]},{"cell_type":"code","source":["!pip install --upgrade --no-cache-dir gdown --quiet"],"metadata":{"id":"i6zvzv3qZ6xS"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hCpOVzJdl8_p"},"source":["import numpy as np\n","import random\n","import io\n","import pickle\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","from keras.utils.np_utils import to_categorical\n","from tensorflow.keras.utils import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Embedding"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8UPeRkrAmbF3"},"source":["### Datos\n","Utilizaremos como dataset críticas de compradores de ropa (eCommerce) los cuales puntuaron a cada prenda con un puntaje de 1 a 5 estrellas.\\\n","Referencia del dataset: [LINK](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews/version/1)"]},{"cell_type":"code","metadata":{"id":"C7jLvTU3lSyL"},"source":["# Descargar la carpeta de dataset\n","import os\n","import gdown\n","if os.access('clothing_ecommerce_reviews.csv', os.F_OK) is False:\n","    url = 'https://drive.google.com/uc?id=1Urn1UFSrodN5BuW6-sc_igtaySGRwhV8'\n","    output = 'clothing_ecommerce_reviews.csv'\n","    gdown.download(url, output, quiet=False)\n","else:\n","    print(\"El dataset ya se encuentra descargado\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o-SV1P3dnD1J"},"source":["# Armar el dataset\n","df = pd.read_csv('clothing_ecommerce_reviews.csv')\n","df.drop(columns = ['Unnamed: 0'], inplace = True)\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q-OwSePKm-FK"},"source":["### 1 - Limpieza de datos\n","Alumno:\n","- Del dataset unicamente utilizar las columnas \"Review Text\" y \"Rating.\n","- Tranformar el rating 1-5 a una escala numérica de 0 a 4.\n","\n"]},{"cell_type":"code","metadata":{"id":"-hc7-AmYnPC3"},"source":["df_reviews = df.loc[:, ['Review Text', 'Rating']].dropna()\n","df_reviews['Rating'] = df_reviews['Rating'] - 1\n","df_reviews.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sZtvASVOn3ty"},"source":["# Alumno: Observar como está distribuido el dataset respecto a la columna Rating\n","# es decir, observar que tan balanceado se encuentra respecot a cada clase"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gVJ_RVi4o1h3"},"source":["# Alumno: tomar la columna de las review y almacenarlo todo en un vector numpy de reviews"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4nT5Un_co65Q"},"source":["# Alumno: Cuantas reviews (rows) hay para evaluar?"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HP5uN9tqpHu_"},"source":["# Alumno: Concatenar todas las reviews para armar el corpus"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FEzmePgdpf74"},"source":["# Alumno: ¿Cuál es la longitud de ese corpus?"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MYeJLdDmpvOe"},"source":["# Alumno: Utilizar \"text_to_word_sequence\" para separar las palabras en tokens\n","# recordar que text_to_word_sequence automaticamente quita los signos de puntuacion y pasa el texto a lowercase\n","from keras.preprocessing.text import text_to_word_sequence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M6L-fnWAp_lA"},"source":["# Alumno: Dar un vistazo a los primeros 20 tokens/palabras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8QgwwMUqG0d"},"source":["# Alumno: ¿Cuántos tokens/palabras hay?"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TFukNZdOsZ8_"},"source":["# Alumno: Tokenizar las palabras con el Tokenizer de Keras\n","# Definir una máxima cantidad de palabras a utilizar:\n","# num_words --> the maximum number of words to keep, based on word frequency.\n","# Only the most common num_words-1 words will be kept.\n","from keras.preprocessing.text import Tokenizer\n","num_words = 2000\n","vocab_size = num_words"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JnR1tlqZy94X"},"source":["# Alumno: Obtener el diccionario de palabra (word) a índice\n","# y observar la cantidad total del vocabulario"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AvWzzSretQXf"},"source":["# Alumno: Convertir las palabras/tokens a números"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"za73M5SRtbrP"},"source":["# Alumno: Determinar cual es la oración más larga"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oCkO9Wc9tls1"},"source":["# Alumno: Realizar padding de las sentencias al mismo tamaño\n","# tomando de referencia la máxima sentencia\n","from tensorflow.keras.utils import pad_sequences\n","maxlen = 115"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kGHHabVdt_aa"},"source":["# Alumno: Observar las dimensiones de la variable input"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"llVM-tzQo9_F"},"source":["# Alumno tomar la columna rating y alcemacenarla en una variable \"y\" transformada a oneHotEncoding\n","# Su shape debe ser equivalente la cantidad de rows del corpus y a la cantidad\n","# de clases que se deseen predecir (en este ejemplo son 5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rmz9A6n4uK4V"},"source":["# Alumno: Dividir los datos en train y test\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EcDPlhEouQ9E"},"source":["# Alumno: determinar la dimensiones de entrada y salida"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NpbQHExL6OTu"},"source":["### 2 - Entrenar el modelo con Embeddings + LSTM"]},{"cell_type":"code","metadata":{"id":"NUkuWBsM6cx3"},"source":["# Alumno: Entrene su modelo con LSTM entrenando sus propios embeddings\n","# o utilizando embeddings pre-entrenados.\n","from keras.layers import LSTM\n","from keras.layers import Embedding\n","from keras.layers import Dropout"],"execution_count":null,"outputs":[]}]}